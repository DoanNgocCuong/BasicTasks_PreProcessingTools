# @DoanNgocCuong
"""
# QUan tr·ªçng nh·∫•t v·∫´n l√† model nh·∫≠n di·ªán tr·∫ª em v√† ng∆∞·ªùi l·ªõn. Code tr√™·ªÉn khai c√°i n√†y tr∆∞·ªõc. Input l√† 1 folder trong ƒë√≥ c√≥ nh√™·ªÅu audio (d·∫°ng .wav)
=> Output mong mu·ªën l√†: Folder output ch·ª©a
1. Folder tr·∫ª em 
2. Folder ng∆∞·ªùi l·ªõn 
3. File excel g·ªìm t√™n file v√† label (tr·∫ª em/ng∆∞·ªùi l·ªõn)
4. File results.txt (ƒë√°nh gi√° Precision, Recall)

Note: D√πng pathlib ƒëi 
File code ƒë·ªÉ ngang b·∫±ng v·ªã tr√≠ v·ªõi folder: input v√† folder output File code ƒë·ªÉ ngang b·∫±ng v·ªã tr√≠ v·ªõi folder: input v√† folder output

---

M·ªói file audio .wav s·∫Ω ƒë∆∞·ª£c ƒë∆∞a qua model wav2vec2 ƒë·ªÉ d·ª± ƒëo√°n nh√£n child/adult.
N·∫øu d·ª± ƒëo√°n l√† "child" v·ªõi ƒë·ªô t·ª± tin (confidence) l·ªõn h∆°n 0.7 th√¨ file s·∫Ω ƒë∆∞·ª£c ch√©p v√†o folder "child", ng∆∞·ª£c l·∫°i v√†o "adult".
T·∫•t c·∫£ k·∫øt qu·∫£ ƒë∆∞·ª£c ghi v√†o file Excel.
N·∫øu c√≥ file groundtruth, code s·∫Ω t√≠nh Precision/Recall v√† ghi ra file results.txt.
"""
"""
H·ªá th·ªëng ph√¢n lo·∫°i gi·ªçng n√≥i tr·∫ª em/ng∆∞·ªùi l·ªõn
Author: @DoanNgocCuong
Description: Ph√¢n lo·∫°i file audio .wav th√†nh tr·∫ª em v√† ng∆∞·ªùi l·ªõn s·ª≠ d·ª•ng wav2vec2
Model: audeering/wav2vec2-large-robust-24-ft-age-gender
"""

import torchaudio
import torch
import torch.nn as nn
import librosa
import numpy as np
import warnings
from transformers import Wav2Vec2Processor
from transformers.models.wav2vec2.modeling_wav2vec2 import (
    Wav2Vec2Model,
    Wav2Vec2PreTrainedModel,
)
from pathlib import Path
import pandas as pd
import shutil
from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix
import logging
from tqdm import tqdm

# T·∫Øt warnings kh√¥ng c·∫ßn thi·∫øt
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ModelHead(nn.Module):
    """Classification head."""

    def __init__(self, config, num_labels):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.dropout = nn.Dropout(config.final_dropout)
        self.out_proj = nn.Linear(config.hidden_size, num_labels)

    def forward(self, features, **kwargs):
        x = features
        x = self.dropout(x)
        x = self.dense(x)
        x = torch.tanh(x)
        x = self.dropout(x)
        x = self.out_proj(x)
        return x


class AgeGenderModel(Wav2Vec2PreTrainedModel):
    """Speech age and gender classifier."""

    def __init__(self, config):
        super().__init__(config)
        self.config = config
        self.wav2vec2 = Wav2Vec2Model(config)
        self.age = ModelHead(config, 1)
        self.gender = ModelHead(config, 3)
        self.init_weights()

    def forward(self, input_values):
        outputs = self.wav2vec2(input_values)
        hidden_states = outputs[0]
        hidden_states = torch.mean(hidden_states, dim=1)
        logits_age = self.age(hidden_states)
        logits_gender = torch.softmax(self.gender(hidden_states), dim=1)
        return hidden_states, logits_age, logits_gender


class AudioClassifier:
    def __init__(self, model_name="audeering/wav2vec2-large-robust-24-ft-age-gender", 
                 child_threshold=0.5, age_threshold=0.3):
        """
        Kh·ªüi t·∫°o classifier v·ªõi model v√† ng∆∞·ª°ng confidence
        
        Args:
            model_name: T√™n model tr√™n Hugging Face
            child_threshold: Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ ph√¢n lo·∫°i tr·∫ª em (child)
            age_threshold: Ng∆∞·ª°ng tu·ªïi ƒë·ªÉ ph√¢n lo·∫°i (0.3 ~ 30 tu·ªïi)
        """
        self.model_name = model_name
        self.child_threshold = child_threshold
        self.age_threshold = age_threshold
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"S·ª≠ d·ª•ng device: {self.device}")
        
        # Load model v√† processor
        try:
            logger.info("ƒêang t·∫£i model...")
            self.processor = Wav2Vec2Processor.from_pretrained(model_name)
            self.model = AgeGenderModel.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            logger.info("T·∫£i model th√†nh c√¥ng!")
        except Exception as e:
            logger.error(f"L·ªói khi t·∫£i model: {e}")
            raise
        
        # Labels: [female, male, child]
        self.gender_labels = ['female', 'male', 'child']
        
    def preprocess_audio(self, audio_path, target_sr=16000):
        """
        Ti·ªÅn x·ª≠ l√Ω file audio
        """
        try:
            # S·ª≠ d·ª•ng librosa ƒë·ªÉ ƒë·ªçc audio
            speech_array, original_sr = librosa.load(audio_path, sr=None)
            
            # Resample n·∫øu c·∫ßn
            if original_sr != target_sr:
                speech_array = librosa.resample(speech_array, orig_sr=original_sr, target_sr=target_sr)
            
            # Normalize audio
            if np.max(np.abs(speech_array)) > 0:
                speech_array = speech_array / np.max(np.abs(speech_array))
            
            return speech_array.astype(np.float32), target_sr
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω audio {audio_path}: {e}")
            return None, None
    
    def predict(self, audio_path):
        """
        D·ª± ƒëo√°n tu·ªïi v√† gi·ªõi t√≠nh cho m·ªôt file audio
        """
        speech_array, sampling_rate = self.preprocess_audio(audio_path)
        if speech_array is None:
            return None, None, None, "error"
        
        try:
            # Process audio
            inputs = self.processor(speech_array, sampling_rate=sampling_rate)
            input_values = inputs['input_values'][0]
            input_values = input_values.reshape(1, -1)
            input_values = torch.from_numpy(input_values).to(self.device)
            
            # Prediction
            with torch.no_grad():
                hidden_states, age_logits, gender_probs = self.model(input_values)
                
                # Age prediction (0-1 scale, 0=0 years, 1=100 years)
                age_normalized = float(age_logits.squeeze())
                age_years = age_normalized * 100  # Convert to years
                
                # Gender prediction probabilities [female, male, child]
                gender_probs = gender_probs.squeeze().cpu().numpy()
                
                return age_normalized, age_years, gender_probs, "success"
                
        except Exception as e:
            logger.error(f"L·ªói khi d·ª± ƒëo√°n {audio_path}: {e}")
            return None, None, None, "error"
    
    def classify_age_group(self, age_normalized, gender_probs):
        """
        Ph√¢n lo·∫°i th√†nh tr·∫ª em ho·∫∑c ng∆∞·ªùi l·ªõn
        
        Logic:
        1. N·∫øu gender_probs[2] (child) > child_threshold -> child
        2. Ho·∫∑c n·∫øu age_normalized < age_threshold -> child  
        3. Ng∆∞·ª£c l·∫°i -> adult
        """
        child_prob = gender_probs[2] if gender_probs is not None else 0
        
        # Ki·ªÉm tra x√°c su·∫•t child
        if child_prob > self.child_threshold:
            return "child", child_prob
        
        # Ho·∫∑c ki·ªÉm tra tu·ªïi
        if age_normalized is not None and age_normalized < self.age_threshold:
            return "child", age_normalized
        
        return "adult", 1 - child_prob


def main():
    # ƒê∆∞·ªùng d·∫´n folder input/output
    input_folder = Path('./input')
    output_folder = Path('./output')
    child_folder = output_folder / 'child'
    adult_folder = output_folder / 'adult'
    
    # Ki·ªÉm tra folder input
    if not input_folder.exists():
        logger.error(f"Folder input kh√¥ng t·ªìn t·∫°i: {input_folder}")
        print("‚ùå T·∫°o folder 'input' v√† ƒë·∫∑t c√°c file .wav v√†o ƒë√≥!")
        return
    
    # T·∫°o c√°c folder output
    output_folder.mkdir(exist_ok=True)
    child_folder.mkdir(exist_ok=True)
    adult_folder.mkdir(exist_ok=True)
    
    # Kh·ªüi t·∫°o classifier
    # B·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh c√°c ng∆∞·ª°ng n√†y:
    # - child_threshold: x√°c su·∫•t child > ng∆∞·ª°ng n√†y -> child
    # - age_threshold: tu·ªïi < ng∆∞·ª°ng n√†y (0.3 = 30 tu·ªïi) -> child
    classifier = AudioClassifier(child_threshold=0.4, age_threshold=0.25)
    
    # T√¨m t·∫•t c·∫£ file wav
    wav_files = list(input_folder.glob('*.wav'))
    if not wav_files:
        logger.error("Kh√¥ng t√¨m th·∫•y file .wav n√†o trong folder input")
        print("‚ùå Kh√¥ng t√¨m th·∫•y file .wav n√†o trong folder 'input'")
        return
    
    logger.info(f"T√¨m th·∫•y {len(wav_files)} file .wav")
    
    # X·ª≠ l√Ω t·ª´ng file
    results = []
    success_count = 0
    error_count = 0
    
    for wav_file in tqdm(wav_files, desc="üéµ ƒêang ph√¢n lo·∫°i audio"):
        # D·ª± ƒëo√°n
        age_norm, age_years, gender_probs, status = classifier.predict(wav_file)
        
        if status == "error":
            error_count += 1
            results.append({
                'filename': wav_file.name,
                'age_normalized': 'error',
                'age_years': 'error',
                'female_prob': 'error',
                'male_prob': 'error', 
                'child_prob': 'error',
                'final_label': 'error',
                'confidence': 0.0,
                'status': 'error'
            })
            continue
        
        # Ph√¢n lo·∫°i age group
        final_label, confidence = classifier.classify_age_group(age_norm, gender_probs)
        
        # Copy file v√†o folder t∆∞∆°ng ·ª©ng
        try:
            if final_label == "child":
                shutil.copy2(wav_file, child_folder / wav_file.name)
            else:
                shutil.copy2(wav_file, adult_folder / wav_file.name)
            success_count += 1
        except Exception as e:
            logger.error(f"L·ªói khi copy file {wav_file.name}: {e}")
            final_label = "error"
            error_count += 1
        
        # L∆∞u k·∫øt qu·∫£
        results.append({
            'filename': wav_file.name,
            'age_normalized': round(age_norm, 4) if age_norm is not None else 'N/A',
            'age_years': round(age_years, 1) if age_years is not None else 'N/A',
            'female_prob': round(gender_probs[0], 4) if gender_probs is not None else 'N/A',
            'male_prob': round(gender_probs[1], 4) if gender_probs is not None else 'N/A',
            'child_prob': round(gender_probs[2], 4) if gender_probs is not None else 'N/A',
            'final_label': final_label,
            'confidence': round(confidence, 4),
            'status': 'success' if final_label != 'error' else 'error'
        })
    
    # Xu·∫•t k·∫øt qu·∫£ ra Excel
    df = pd.DataFrame(results)
    excel_path = output_folder / 'classification_results.xlsx'
    
    try:
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Results', index=False)
            
            # Th√™m sheet th·ªëng k√™
            child_count = len(df[df['final_label'] == 'child'])
            adult_count = len(df[df['final_label'] == 'adult'])
            
            stats_df = pd.DataFrame({
                'Metric': [
                    'Total Files', 'Success', 'Error', 'Child', 'Adult', 
                    'Success Rate', 'Child Rate', 'Adult Rate'
                ],
                'Value': [
                    len(wav_files),
                    success_count,
                    error_count,
                    child_count,
                    adult_count,
                    f"{(success_count/len(wav_files)*100):.2f}%",
                    f"{(child_count/len(wav_files)*100):.2f}%",
                    f"{(adult_count/len(wav_files)*100):.2f}%"
                ]
            })
            stats_df.to_excel(writer, sheet_name='Statistics', index=False)

            # Th√™m sheet cho child, adult, all
            df_child = df[df['final_label'] == 'child']
            df_adult = df[df['final_label'] == 'adult']
            df_child.to_excel(writer, sheet_name='child', index=False)
            df_adult.to_excel(writer, sheet_name='adult', index=False)
            df.to_excel(writer, sheet_name='all', index=False)
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {excel_path}")
    except Exception as e:
        logger.error(f"L·ªói khi xu·∫•t Excel: {e}")
    
    # T√≠nh Precision/Recall n·∫øu c√≥ groundtruth
    groundtruth_path = input_folder / 'groundtruth.csv'
    results_txt_path = output_folder / 'results.txt'
    
    try:
        with open(results_txt_path, 'w', encoding='utf-8') as f:
            f.write("=== K·∫æT QU·∫¢ PH√ÇN LO·∫†I AUDIO TR·∫∫ EM/NG∆Ø·ªúI L·ªöN ===\n\n")
            f.write(f"üìä Model: {classifier.model_name}\n")
            f.write(f"üéØ Ng∆∞·ª°ng Child Probability: {classifier.child_threshold}\n")
            f.write(f"üéØ Ng∆∞·ª°ng Age: {classifier.age_threshold} ({classifier.age_threshold*100} tu·ªïi)\n\n")
            
            f.write("üìà TH·ªêNG K√ä T·ªîNG QU√ÅT:\n")
            f.write(f"T·ªïng s·ªë file: {len(wav_files)}\n")
            f.write(f"Th√†nh c√¥ng: {success_count}\n")
            f.write(f"L·ªói: {error_count}\n")
            f.write(f"Tr·∫ª em: {child_count}\n")
            f.write(f"Ng∆∞·ªùi l·ªõn: {adult_count}\n")
            f.write(f"T·ª∑ l·ªá th√†nh c√¥ng: {(success_count/len(wav_files)*100):.2f}%\n")
            f.write(f"T·ª∑ l·ªá tr·∫ª em: {(child_count/len(wav_files)*100):.2f}%\n")
            f.write(f"T·ª∑ l·ªá ng∆∞·ªùi l·ªõn: {(adult_count/len(wav_files)*100):.2f}%\n\n")
            
            if groundtruth_path.exists():
                try:
                    gt_df = pd.read_csv(groundtruth_path)
                    # Merge v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n
                    merged = df.merge(gt_df, on='filename', how='inner')
                    
                    if len(merged) > 0:
                        # Ch·ªâ t√≠nh v·ªõi c√°c sample th√†nh c√¥ng
                        valid_merged = merged[merged['status'] == 'success']
                        
                        if len(valid_merged) > 0:
                            y_true = valid_merged['true_label']
                            y_pred = valid_merged['final_label']
                            
                            # T√≠nh metrics
                            labels = ['adult', 'child']
                            precision = precision_score(y_true, y_pred, labels=labels, average=None, zero_division=0)
                            recall = recall_score(y_true, y_pred, labels=labels, average=None, zero_division=0)
                            
                            f.write("üéØ ƒê√ÅNH GI√Å V·ªöI GROUNDTRUTH:\n")
                            f.write(f"S·ªë sample c√≥ groundtruth: {len(valid_merged)}\n")
                            f.write(f"Precision (Adult): {precision[0]:.4f}\n")
                            f.write(f"Recall (Adult): {recall[0]:.4f}\n")
                            f.write(f"Precision (Child): {precision[1]:.4f}\n")
                            f.write(f"Recall (Child): {recall[1]:.4f}\n\n")
                            
                            # Classification report
                            f.write("üìã Classification Report:\n")
                            f.write(classification_report(y_true, y_pred, target_names=labels))
                            f.write("\n")
                            
                            # Confusion Matrix
                            f.write("üî¢ Confusion Matrix:\n")
                            f.write("    Predicted\n")
                            f.write("    Adult Child\n")
                            cm = confusion_matrix(y_true, y_pred, labels=labels)
                            f.write(f"Adult  {cm[0][0]:3d}   {cm[0][1]:3d}\n")
                            f.write(f"Child  {cm[1][0]:3d}   {cm[1][1]:3d}\n")
                            f.write("Actual\n\n")
                        else:
                            f.write("‚ùå Kh√¥ng c√≥ sample th√†nh c√¥ng ƒë·ªÉ ƒë√°nh gi√°.\n")
                    else:
                        f.write("‚ùå Kh√¥ng c√≥ sample n√†o match v·ªõi groundtruth.\n")
                        
                except Exception as e:
                    f.write(f"‚ùå L·ªói khi x·ª≠ l√Ω groundtruth: {e}\n")
            else:
                f.write("üìù H∆Ø·ªöNG D·∫™N T·∫†O GROUNDTRUTH:\n")
                f.write("ƒê·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c, t·∫°o file groundtruth.csv v·ªõi format:\n")
                f.write("filename,true_label\n")
                f.write("audio1.wav,child\n")
                f.write("audio2.wav,adult\n\n")
        
        logger.info(f"‚úÖ ƒê√£ l∆∞u b√°o c√°o v√†o: {results_txt_path}")
        
    except Exception as e:
        logger.error(f"L·ªói khi t·∫°o b√°o c√°o: {e}")
    
    # In k·∫øt qu·∫£ t·ªïng k·∫øt
    print("\n" + "="*60)
    print("üéµ K·∫æT QU·∫¢ PH√ÇN LO·∫†I GI·ªåNG N√ìI TR·∫∫ EM/NG∆Ø·ªúI L·ªöN")
    print("="*60)
    print(f"üìÅ T·ªïng s·ªë file x·ª≠ l√Ω: {len(wav_files)}")
    print(f"‚úÖ Th√†nh c√¥ng: {success_count}")
    print(f"‚ùå L·ªói: {error_count}")
    print(f"üë∂ Tr·∫ª em: {child_count} ({(child_count/len(wav_files)*100):.1f}%)")
    print(f"üë® Ng∆∞·ªùi l·ªõn: {adult_count} ({(adult_count/len(wav_files)*100):.1f}%)")
    print(f"üìä T·ª∑ l·ªá th√†nh c√¥ng: {(success_count/len(wav_files)*100):.2f}%")
    print("\nüìÇ C√°c file output:")
    print(f"   üìÅ {child_folder} - Ch·ª©a {child_count} file tr·∫ª em")
    print(f"   üìÅ {adult_folder} - Ch·ª©a {adult_count} file ng∆∞·ªùi l·ªõn") 
    print(f"   üìä {excel_path} - K·∫øt qu·∫£ chi ti·∫øt")
    print(f"   üìù {results_txt_path} - B√°o c√°o ƒë√°nh gi√°")
    print("="*60)
    
    if child_count == 0:
        print("‚ö†Ô∏è  C·∫¢NH B√ÅO: Kh√¥ng ph√°t hi·ªán file tr·∫ª em n√†o!")
        print("üí° Th·ª≠ gi·∫£m child_threshold ho·∫∑c tƒÉng age_threshold trong code")
    elif adult_count == 0:
        print("‚ö†Ô∏è  C·∫¢NH B√ÅO: Kh√¥ng ph√°t hi·ªán file ng∆∞·ªùi l·ªõn n√†o!")
        print("üí° Th·ª≠ tƒÉng child_threshold ho·∫∑c gi·∫£m age_threshold trong code")


if __name__ == "__main__":
    main()
