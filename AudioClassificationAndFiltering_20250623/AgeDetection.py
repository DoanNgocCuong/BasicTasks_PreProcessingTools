# @DoanNgocCuong
"""
# QUan trá»ng nháº¥t váº«n lÃ  model nháº­n diá»‡n tráº» em vÃ  ngÆ°á»i lá»›n. Code trÃªá»ƒn khai cÃ¡i nÃ y trÆ°á»›c. Input lÃ  1 folder trong Ä‘Ã³ cÃ³ nhÃªá»u audio (dáº¡ng .wav)
=> Output mong muá»‘n lÃ : Folder output chá»©a
1. Folder tráº» em 
2. Folder ngÆ°á»i lá»›n 
3. File excel gá»“m tÃªn file vÃ  label (tráº» em/ngÆ°á»i lá»›n)
4. File results.txt (Ä‘Ã¡nh giÃ¡ Precision, Recall)

Note: DÃ¹ng pathlib Ä‘i 
File code Ä‘á»ƒ ngang báº±ng vá»‹ trÃ­ vá»›i folder: input vÃ  folder output File code Ä‘á»ƒ ngang báº±ng vá»‹ trÃ­ vá»›i folder: input vÃ  folder output

---

Má»—i file audio .wav sáº½ Ä‘Æ°á»£c Ä‘Æ°a qua model wav2vec2 Ä‘á»ƒ dá»± Ä‘oÃ¡n nhÃ£n child/adult.
Náº¿u dá»± Ä‘oÃ¡n lÃ  "child" vá»›i Ä‘á»™ tá»± tin (confidence) lá»›n hÆ¡n 0.7 thÃ¬ file sáº½ Ä‘Æ°á»£c chÃ©p vÃ o folder "child", ngÆ°á»£c láº¡i vÃ o "adult".
Táº¥t cáº£ káº¿t quáº£ Ä‘Æ°á»£c ghi vÃ o file Excel.
Náº¿u cÃ³ file groundtruth, code sáº½ tÃ­nh Precision/Recall vÃ  ghi ra file results.txt.
"""
"""
Há»‡ thá»‘ng phÃ¢n loáº¡i giá»ng nÃ³i tráº» em/ngÆ°á»i lá»›n
Author: @DoanNgocCuong
Description: PhÃ¢n loáº¡i file audio .wav thÃ nh tráº» em vÃ  ngÆ°á»i lá»›n sá»­ dá»¥ng wav2vec2
Model: audeering/wav2vec2-large-robust-24-ft-age-gender
"""

import torchaudio
import torch
import torch.nn as nn
import librosa
import numpy as np
import warnings
from transformers import Wav2Vec2Processor
from transformers.models.wav2vec2.modeling_wav2vec2 import (
    Wav2Vec2Model,
    Wav2Vec2PreTrainedModel,
)
from pathlib import Path
import pandas as pd
import shutil
from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix
import logging
from tqdm import tqdm

# Táº¯t warnings khÃ´ng cáº§n thiáº¿t
warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ModelHead(nn.Module):
    """Classification head."""

    def __init__(self, config, num_labels):
        super().__init__()
        self.dense = nn.Linear(config.hidden_size, config.hidden_size)
        self.dropout = nn.Dropout(config.final_dropout)
        self.out_proj = nn.Linear(config.hidden_size, num_labels)

    def forward(self, features, **kwargs):
        x = features
        x = self.dropout(x)
        x = self.dense(x)
        x = torch.tanh(x)
        x = self.dropout(x)
        x = self.out_proj(x)
        return x


class AgeGenderModel(Wav2Vec2PreTrainedModel):
    """Speech age and gender classifier."""

    def __init__(self, config):
        super().__init__(config)
        self.config = config
        self.wav2vec2 = Wav2Vec2Model(config)
        self.age = ModelHead(config, 1)
        self.gender = ModelHead(config, 3)
        self.init_weights()

    def forward(self, input_values):
        outputs = self.wav2vec2(input_values)
        hidden_states = outputs[0]
        hidden_states = torch.mean(hidden_states, dim=1)
        logits_age = self.age(hidden_states)
        logits_gender = torch.softmax(self.gender(hidden_states), dim=1)
        return hidden_states, logits_age, logits_gender


class AudioClassifier:
    def __init__(self, model_name="audeering/wav2vec2-large-robust-24-ft-age-gender", 
                 child_threshold=0.5, age_threshold=0.3):
        """
        Khá»Ÿi táº¡o classifier vá»›i model vÃ  ngÆ°á»¡ng confidence
        
        Args:
            model_name: TÃªn model trÃªn Hugging Face
            child_threshold: NgÆ°á»¡ng xÃ¡c suáº¥t Ä‘á»ƒ phÃ¢n loáº¡i tráº» em (child)
            age_threshold: NgÆ°á»¡ng tuá»•i Ä‘á»ƒ phÃ¢n loáº¡i (0.3 ~ 30 tuá»•i)
        """
        self.model_name = model_name
        self.child_threshold = child_threshold
        self.age_threshold = age_threshold
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"Sá»­ dá»¥ng device: {self.device}")
        
        # Load model vÃ  processor
        try:
            logger.info("Äang táº£i model...")
            self.processor = Wav2Vec2Processor.from_pretrained(model_name)
            self.model = AgeGenderModel.from_pretrained(model_name)
            self.model.to(self.device)
            self.model.eval()
            logger.info("Táº£i model thÃ nh cÃ´ng!")
        except Exception as e:
            logger.error(f"Lá»—i khi táº£i model: {e}")
            raise
        
        # Labels: [female, male, child]
        self.gender_labels = ['female', 'male', 'child']
        
    def preprocess_audio(self, audio_path, target_sr=16000):
        """
        Tiá»n xá»­ lÃ½ file audio
        """
        try:
            # Sá»­ dá»¥ng librosa Ä‘á»ƒ Ä‘á»c audio
            speech_array, original_sr = librosa.load(audio_path, sr=None)
            
            # Resample náº¿u cáº§n
            if original_sr != target_sr:
                speech_array = librosa.resample(speech_array, orig_sr=original_sr, target_sr=target_sr)
            
            # Normalize audio
            if np.max(np.abs(speech_array)) > 0:
                speech_array = speech_array / np.max(np.abs(speech_array))
            
            return speech_array.astype(np.float32), target_sr
        except Exception as e:
            logger.error(f"Lá»—i khi xá»­ lÃ½ audio {audio_path}: {e}")
            return None, None
    
    def predict(self, audio_path):
        """
        Dá»± Ä‘oÃ¡n tuá»•i vÃ  giá»›i tÃ­nh cho má»™t file audio
        """
        speech_array, sampling_rate = self.preprocess_audio(audio_path)
        if speech_array is None:
            return None, None, None, "error"
        
        try:
            # Process audio
            inputs = self.processor(speech_array, sampling_rate=sampling_rate)
            input_values = inputs['input_values'][0]
            input_values = input_values.reshape(1, -1)
            input_values = torch.from_numpy(input_values).to(self.device)
            
            # Prediction
            with torch.no_grad():
                hidden_states, age_logits, gender_probs = self.model(input_values)
                
                # Age prediction (0-1 scale, 0=0 years, 1=100 years)
                age_normalized = float(age_logits.squeeze())
                age_years = age_normalized * 100  # Convert to years
                
                # Gender prediction probabilities [female, male, child]
                gender_probs = gender_probs.squeeze().cpu().numpy()
                
                return age_normalized, age_years, gender_probs, "success"
                
        except Exception as e:
            logger.error(f"Lá»—i khi dá»± Ä‘oÃ¡n {audio_path}: {e}")
            return None, None, None, "error"
    
    def classify_age_group(self, age_normalized, gender_probs):
        """
        PhÃ¢n loáº¡i thÃ nh tráº» em hoáº·c ngÆ°á»i lá»›n
        
        Logic:
        1. Náº¿u gender_probs[2] (child) > child_threshold -> child
        2. Hoáº·c náº¿u age_normalized < age_threshold -> child  
        3. NgÆ°á»£c láº¡i -> adult
        """
        child_prob = gender_probs[2] if gender_probs is not None else 0
        
        # Kiá»ƒm tra xÃ¡c suáº¥t child
        if child_prob > self.child_threshold:
            return "child", child_prob
        
        # Hoáº·c kiá»ƒm tra tuá»•i
        if age_normalized is not None and age_normalized < self.age_threshold:
            return "child", age_normalized
        
        return "adult", 1 - child_prob


def main():
    # ÄÆ°á»ng dáº«n folder input/output
    input_folder = Path('./input')
    output_folder = Path('./output')
    child_folder = output_folder / 'child'
    adult_folder = output_folder / 'adult'
    
    # Kiá»ƒm tra folder input
    if not input_folder.exists():
        logger.error(f"Folder input khÃ´ng tá»“n táº¡i: {input_folder}")
        print("âŒ Táº¡o folder 'input' vÃ  Ä‘áº·t cÃ¡c file .wav vÃ o Ä‘Ã³!")
        return
    
    # Táº¡o cÃ¡c folder output
    output_folder.mkdir(exist_ok=True)
    child_folder.mkdir(exist_ok=True)
    adult_folder.mkdir(exist_ok=True)
    
    # Khá»Ÿi táº¡o classifier
    # Báº¡n cÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ¡c ngÆ°á»¡ng nÃ y:
    # - child_threshold: xÃ¡c suáº¥t child > ngÆ°á»¡ng nÃ y -> child
    # - age_threshold: tuá»•i < ngÆ°á»¡ng nÃ y (0.3 = 30 tuá»•i) -> child
    classifier = AudioClassifier(child_threshold=0.4, age_threshold=0.25)
    
    # TÃ¬m táº¥t cáº£ file wav
    wav_files = list(input_folder.glob('*.wav'))
    if not wav_files:
        logger.error("KhÃ´ng tÃ¬m tháº¥y file .wav nÃ o trong folder input")
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file .wav nÃ o trong folder 'input'")
        return
    
    logger.info(f"TÃ¬m tháº¥y {len(wav_files)} file .wav")
    
    # Xá»­ lÃ½ tá»«ng file
    results = []
    success_count = 0
    error_count = 0
    
    for wav_file in tqdm(wav_files, desc="ğŸµ Äang phÃ¢n loáº¡i audio"):
        # Dá»± Ä‘oÃ¡n
        age_norm, age_years, gender_probs, status = classifier.predict(wav_file)
        
        if status == "error":
            error_count += 1
            results.append({
                'filename': wav_file.name,
                'age_normalized': 'error',
                'age_years': 'error',
                'female_prob': 'error',
                'male_prob': 'error', 
                'child_prob': 'error',
                'final_label': 'error',
                'confidence': 0.0,
                'status': 'error'
            })
            continue
        
        # PhÃ¢n loáº¡i age group
        final_label, confidence = classifier.classify_age_group(age_norm, gender_probs)
        
        # Copy file vÃ o folder tÆ°Æ¡ng á»©ng
        try:
            if final_label == "child":
                shutil.copy2(wav_file, child_folder / wav_file.name)
            else:
                shutil.copy2(wav_file, adult_folder / wav_file.name)
            success_count += 1
        except Exception as e:
            logger.error(f"Lá»—i khi copy file {wav_file.name}: {e}")
            final_label = "error"
            error_count += 1
        
        # LÆ°u káº¿t quáº£
        results.append({
            'filename': wav_file.name,
            'age_normalized': round(age_norm, 4) if age_norm is not None else 'N/A',
            'age_years': round(age_years, 1) if age_years is not None else 'N/A',
            'female_prob': round(gender_probs[0], 4) if gender_probs is not None else 'N/A',
            'male_prob': round(gender_probs[1], 4) if gender_probs is not None else 'N/A',
            'child_prob': round(gender_probs[2], 4) if gender_probs is not None else 'N/A',
            'final_label': final_label,
            'confidence': round(confidence, 4),
            'status': 'success' if final_label != 'error' else 'error'
        })
    
    # Xuáº¥t káº¿t quáº£ ra Excel
    df = pd.DataFrame(results)
    excel_path = output_folder / 'classification_results.xlsx'
    
    try:
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Results', index=False)
            
            # ThÃªm sheet thá»‘ng kÃª
            child_count = len(df[df['final_label'] == 'child'])
            adult_count = len(df[df['final_label'] == 'adult'])
            
            stats_df = pd.DataFrame({
                'Metric': [
                    'Total Files', 'Success', 'Error', 'Child', 'Adult', 
                    'Success Rate', 'Child Rate', 'Adult Rate'
                ],
                'Value': [
                    len(wav_files),
                    success_count,
                    error_count,
                    child_count,
                    adult_count,
                    f"{(success_count/len(wav_files)*100):.2f}%",
                    f"{(child_count/len(wav_files)*100):.2f}%",
                    f"{(adult_count/len(wav_files)*100):.2f}%"
                ]
            })
            stats_df.to_excel(writer, sheet_name='Statistics', index=False)

            # ThÃªm sheet cho child, adult, all
            df_child = df[df['final_label'] == 'child']
            df_adult = df[df['final_label'] == 'adult']
            df_child.to_excel(writer, sheet_name='child', index=False)
            df_adult.to_excel(writer, sheet_name='adult', index=False)
            df.to_excel(writer, sheet_name='all', index=False)
        
        logger.info(f"âœ… ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {excel_path}")
    except Exception as e:
        logger.error(f"Lá»—i khi xuáº¥t Excel: {e}")
    
    # TÃ­nh Precision/Recall náº¿u cÃ³ groundtruth
    groundtruth_path = input_folder / 'groundtruth.csv'
    results_txt_path = output_folder / 'results.txt'
    
    try:
        with open(results_txt_path, 'w', encoding='utf-8') as f:
            f.write("=== Káº¾T QUáº¢ PHÃ‚N LOáº I AUDIO TRáºº EM/NGÆ¯á»œI Lá»šN ===\n\n")
            f.write(f"ğŸ“Š Model: {classifier.model_name}\n")
            f.write(f"ğŸ¯ NgÆ°á»¡ng Child Probability: {classifier.child_threshold}\n")
            f.write(f"ğŸ¯ NgÆ°á»¡ng Age: {classifier.age_threshold} ({classifier.age_threshold*100} tuá»•i)\n\n")
            
            f.write("ğŸ“ˆ THá»NG KÃŠ Tá»”NG QUÃT:\n")
            f.write(f"Tá»•ng sá»‘ file: {len(wav_files)}\n")
            f.write(f"ThÃ nh cÃ´ng: {success_count}\n")
            f.write(f"Lá»—i: {error_count}\n")
            f.write(f"Tráº» em: {child_count}\n")
            f.write(f"NgÆ°á»i lá»›n: {adult_count}\n")
            f.write(f"Tá»· lá»‡ thÃ nh cÃ´ng: {(success_count/len(wav_files)*100):.2f}%\n")
            f.write(f"Tá»· lá»‡ tráº» em: {(child_count/len(wav_files)*100):.2f}%\n")
            f.write(f"Tá»· lá»‡ ngÆ°á»i lá»›n: {(adult_count/len(wav_files)*100):.2f}%\n\n")
            
            if groundtruth_path.exists():
                try:
                    gt_df = pd.read_csv(groundtruth_path)
                    # Merge vá»›i káº¿t quáº£ dá»± Ä‘oÃ¡n
                    merged = df.merge(gt_df, on='filename', how='inner')
                    
                    if len(merged) > 0:
                        # Chá»‰ tÃ­nh vá»›i cÃ¡c sample thÃ nh cÃ´ng
                        valid_merged = merged[merged['status'] == 'success']
                        
                        if len(valid_merged) > 0:
                            y_true = valid_merged['true_label']
                            y_pred = valid_merged['final_label']
                            
                            # TÃ­nh metrics
                            labels = ['adult', 'child']
                            precision = precision_score(y_true, y_pred, labels=labels, average=None, zero_division=0)
                            recall = recall_score(y_true, y_pred, labels=labels, average=None, zero_division=0)
                            
                            f.write("ğŸ¯ ÄÃNH GIÃ Vá»šI GROUNDTRUTH:\n")
                            f.write(f"Sá»‘ sample cÃ³ groundtruth: {len(valid_merged)}\n")
                            f.write(f"Precision (Adult): {precision[0]:.4f}\n")
                            f.write(f"Recall (Adult): {recall[0]:.4f}\n")
                            f.write(f"Precision (Child): {precision[1]:.4f}\n")
                            f.write(f"Recall (Child): {recall[1]:.4f}\n\n")
                            
                            # Classification report
                            f.write("ğŸ“‹ Classification Report:\n")
                            f.write(classification_report(y_true, y_pred, target_names=labels))
                            f.write("\n")
                            
                            # Confusion Matrix
                            f.write("ğŸ”¢ Confusion Matrix:\n")
                            f.write("    Predicted\n")
                            f.write("    Adult Child\n")
                            cm = confusion_matrix(y_true, y_pred, labels=labels)
                            f.write(f"Adult  {cm[0][0]:3d}   {cm[0][1]:3d}\n")
                            f.write(f"Child  {cm[1][0]:3d}   {cm[1][1]:3d}\n")
                            f.write("Actual\n\n")
                        else:
                            f.write("âŒ KhÃ´ng cÃ³ sample thÃ nh cÃ´ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.\n")
                    else:
                        f.write("âŒ KhÃ´ng cÃ³ sample nÃ o match vá»›i groundtruth.\n")
                        
                except Exception as e:
                    f.write(f"âŒ Lá»—i khi xá»­ lÃ½ groundtruth: {e}\n")
            else:
                f.write("ğŸ“ HÆ¯á»šNG DáºªN Táº O GROUNDTRUTH:\n")
                f.write("Äá»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c, táº¡o file groundtruth.csv vá»›i format:\n")
                f.write("filename,true_label\n")
                f.write("audio1.wav,child\n")
                f.write("audio2.wav,adult\n\n")
        
        logger.info(f"âœ… ÄÃ£ lÆ°u bÃ¡o cÃ¡o vÃ o: {results_txt_path}")
        
    except Exception as e:
        logger.error(f"Lá»—i khi táº¡o bÃ¡o cÃ¡o: {e}")
    
    # In káº¿t quáº£ tá»•ng káº¿t
    print("\n" + "="*60)
    print("ğŸµ Káº¾T QUáº¢ PHÃ‚N LOáº I GIá»ŒNG NÃ“I TRáºº EM/NGÆ¯á»œI Lá»šN")
    print("="*60)
    print(f"ğŸ“ Tá»•ng sá»‘ file xá»­ lÃ½: {len(wav_files)}")
    print(f"âœ… ThÃ nh cÃ´ng: {success_count}")
    print(f"âŒ Lá»—i: {error_count}")
    print(f"ğŸ‘¶ Tráº» em: {child_count} ({(child_count/len(wav_files)*100):.1f}%)")
    print(f"ğŸ‘¨ NgÆ°á»i lá»›n: {adult_count} ({(adult_count/len(wav_files)*100):.1f}%)")
    print(f"ğŸ“Š Tá»· lá»‡ thÃ nh cÃ´ng: {(success_count/len(wav_files)*100):.2f}%")
    print("\nğŸ“‚ CÃ¡c file output:")
    print(f"   ğŸ“ {child_folder} - Chá»©a {child_count} file tráº» em")
    print(f"   ğŸ“ {adult_folder} - Chá»©a {adult_count} file ngÆ°á»i lá»›n") 
    print(f"   ğŸ“Š {excel_path} - Káº¿t quáº£ chi tiáº¿t")
    print(f"   ğŸ“ {results_txt_path} - BÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡")
    print("="*60)
    
    if child_count == 0:
        print("âš ï¸  Cáº¢NH BÃO: KhÃ´ng phÃ¡t hiá»‡n file tráº» em nÃ o!")
        print("ğŸ’¡ Thá»­ giáº£m child_threshold hoáº·c tÄƒng age_threshold trong code")
    elif adult_count == 0:
        print("âš ï¸  Cáº¢NH BÃO: KhÃ´ng phÃ¡t hiá»‡n file ngÆ°á»i lá»›n nÃ o!")
        print("ğŸ’¡ Thá»­ tÄƒng child_threshold hoáº·c giáº£m age_threshold trong code")


if __name__ == "__main__":
    main()
