{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chào bạn!\n",
    "\n",
    "Rất vui khi thấy bạn đã tiến triển với dự án của mình. Dựa trên yêu cầu của bạn, bạn đang cân nhắc giữa hai phương pháp để xử lý hàng loạt video YouTube:\n",
    "\n",
    "1. **Sử dụng API hiện tại để chạy hàng loạt video**: Gửi nhiều yêu cầu tới API của bạn để xử lý từng video một.\n",
    "2. **Chuyển đổi API sang script để xử lý hàng loạt video cục bộ**: Viết một script Python riêng biệt để xử lý nhiều video cùng lúc mà không cần phải gửi nhiều yêu cầu HTTP tới API.\n",
    "\n",
    "Dưới đây, tôi sẽ phân tích chi tiết cả hai phương pháp, ưu và nhược điểm của từng phương pháp, cũng như cung cấp hướng dẫn cụ thể để bạn có thể lựa chọn phương pháp phù hợp nhất với nhu cầu của mình.\n",
    "\n",
    "---\n",
    "\n",
    "## **Phương Pháp 1: Sử Dụng API Hiện Tại để Chạy Hàng Loạt Video**\n",
    "\n",
    "### **Ưu Điểm:**\n",
    "\n",
    "1. **Tính linh hoạt và mở rộng**: Bạn có thể dễ dàng tích hợp API này vào các ứng dụng web hoặc dịch vụ khác.\n",
    "2. **Bảo mật**: API Key giúp bảo vệ tài nguyên và kiểm soát truy cập.\n",
    "3. **Quản lý dễ dàng**: Bạn có thể triển khai API trên các nền tảng như Google Cloud Functions, AWS Lambda, Heroku, v.v., để dễ dàng mở rộng khi cần.\n",
    "\n",
    "### **Nhược Điểm:**\n",
    "\n",
    "1. **Tốc độ và hiệu suất**: Gửi nhiều yêu cầu HTTP có thể chậm và tăng độ trễ do giới hạn về tốc độ mạng và khả năng xử lý của server.\n",
    "2. **Giới hạn về tỷ lệ yêu cầu**: Các nền tảng API thường có giới hạn về số lượng yêu cầu mỗi phút hoặc mỗi ngày, có thể gây ra lỗi nếu bạn gửi quá nhiều yêu cầu.\n",
    "3. **Phức tạp trong việc quản lý đồng thời**: Nếu bạn cần xử lý hàng nghìn video, việc gửi nhiều yêu cầu đồng thời có thể gây ra các vấn đề về tài nguyên và quản lý.\n",
    "\n",
    "### **Cách Triển Khai Hàng Loạt qua API:**\n",
    "\n",
    "Để sử dụng API hiện tại của bạn để xử lý hàng loạt video, bạn có thể viết một script Python riêng biệt (tách biệt với API) để gửi nhiều yêu cầu tới API của bạn. Dưới đây là ví dụ về cách thực hiện điều này:\n",
    "\n",
    "#### **1. Tạo File `batch_process.py`**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Địa chỉ URL của API của bạn\n",
    "API_URL = \"https://your-api-endpoint.com/get_youtube_transcript\"\n",
    "\n",
    "# API Key cho API của bạn\n",
    "CLIENT_API_KEY = \"yt2024_k8hj3n5m9p2q4w7r\"\n",
    "\n",
    "# Danh sách các URL YouTube bạn muốn xử lý\n",
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=VIDEO_ID_1\",\n",
    "    \"https://www.youtube.com/watch?v=VIDEO_ID_2\",\n",
    "    \"https://www.youtube.com/watch?v=VIDEO_ID_3\",\n",
    "    # Thêm các URL khác ở đây\n",
    "]\n",
    "\n",
    "# Hàm gửi yêu cầu tới API\n",
    "def process_video(url):\n",
    "    headers = {\n",
    "        'X-API-Key': CLIENT_API_KEY,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    params = {\n",
    "        'youtube_url': url\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(API_URL, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Lỗi khi xử lý video {url}: {str(e)}\")\n",
    "        return {\"error\": str(e), \"url\": url}\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    max_workers = 5  # Số lượng luồng song song\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_url = {executor.submit(process_video, url): url for url in youtube_urls}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results.append(data)\n",
    "                print(f\"Đã xử lý xong video: {url}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xử lý video {url}: {str(e)}\")\n",
    "\n",
    "    # Lưu kết quả vào file JSON\n",
    "    with open('batch_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Đã lưu kết quả vào 'batch_results.json'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "#### **2. Giải Thích Script:**\n",
    "\n",
    "- **ThreadPoolExecutor**: Sử dụng để gửi nhiều yêu cầu song song, giúp tăng tốc quá trình xử lý.\n",
    "- **max_workers**: Xác định số lượng luồng song song. Bạn có thể điều chỉnh số này dựa trên khả năng của API và tài nguyên hệ thống.\n",
    "- **Lưu trữ kết quả**: Kết quả được lưu vào file `batch_results.json` để dễ dàng kiểm tra và xử lý sau này.\n",
    "\n",
    "#### **3. Chạy Script:**\n",
    "\n",
    "```bash\n",
    "python batch_process.py\n",
    "```\n",
    "\n",
    "#### **4. Lưu Ý:**\n",
    "\n",
    "- **Giới hạn Tỷ lệ Yêu cầu**: Đảm bảo rằng bạn không vượt quá giới hạn tỷ lệ yêu cầu của API để tránh bị chặn. Bạn có thể thêm `time.sleep()` vào hàm `process_video` nếu cần thiết.\n",
    "  \n",
    "- **Xử Lý Lỗi**: Script đã bao gồm cơ chế xử lý lỗi cơ bản, nhưng bạn có thể mở rộng thêm để xử lý các trường hợp phức tạp hơn.\n",
    "\n",
    "---\n",
    "\n",
    "## **Phương Pháp 2: Chuyển Đổi API Sang Script để Xử Lý Hàng Loạt Video Cục Bộ**\n",
    "\n",
    "### **Ưu Điểm:**\n",
    "\n",
    "1. **Tốc độ và hiệu suất**: Xử lý trực tiếp cục bộ có thể nhanh hơn do không phải qua nhiều bước trung gian như gửi yêu cầu HTTP.\n",
    "2. **Không bị giới hạn tỷ lệ yêu cầu**: Bạn không phải lo lắng về giới hạn tỷ lệ yêu cầu của API.\n",
    "3. **Dễ dàng quản lý và bảo trì**: Bạn có thể dễ dàng kiểm soát và tùy chỉnh quá trình xử lý hàng loạt theo nhu cầu.\n",
    "\n",
    "### **Nhược Điểm:**\n",
    "\n",
    "1. **Bảo mật**: API Key được lưu trữ cục bộ có thể gặp rủi ro về bảo mật nếu không được quản lý đúng cách.\n",
    "2. **Tài nguyên hệ thống**: Xử lý hàng loạt video đòi hỏi tài nguyên hệ thống cao hơn, đặc biệt nếu bạn xử lý nhiều video cùng lúc.\n",
    "3. **Khả năng mở rộng**: Nếu bạn cần xử lý hàng ngàn video thường xuyên, script cục bộ có thể không phù hợp như một API triển khai trên cloud.\n",
    "\n",
    "### **Cách Triển Khai Hàng Loạt qua Script:**\n",
    "\n",
    "Bạn có thể sử dụng script API hiện tại của mình và mở rộng nó để xử lý nhiều video cùng lúc. Dưới đây là hướng dẫn chi tiết.\n",
    "\n",
    "#### **1. Tạo File `batch_script.py`**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import timedelta\n",
    "\n",
    "# Tải biến môi trường từ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Có thể thay đổi thành logging.DEBUG để xem chi tiết hơn\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Rapid API key từ environment variable \n",
    "RAPID_API_KEY = os.environ.get('RAPID_API_KEY')\n",
    "if not RAPID_API_KEY:\n",
    "    logger.error(\"RAPID_API_KEY not found in environment variables\")\n",
    "    raise ValueError(\"Missing RAPID_API_KEY in environment\")\n",
    "\n",
    "logger.info(f\"RAPID_API_KEY loaded: {RAPID_API_KEY[:5]}...\")  # Log 5 ký tự đầu để kiểm tra\n",
    "\n",
    "# Hàm trích xuất video ID từ URL YouTube\n",
    "def extract_video_id(youtube_url):\n",
    "    \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "    try:\n",
    "        # Thêm https:// nếu URL không có\n",
    "        if not youtube_url.startswith(('http://', 'https://')):\n",
    "            youtube_url = 'https://' + youtube_url\n",
    "                \n",
    "        parsed_url = urlparse(youtube_url)\n",
    "            \n",
    "        # Kiểm tra hostname hợp lệ\n",
    "        if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "            elif parsed_url.path.startswith('/embed/'):\n",
    "                return parsed_url.path.split('/')[2]\n",
    "            elif parsed_url.path.startswith('/v/'):\n",
    "                return parsed_url.path.split('/')[2]\n",
    "                    \n",
    "        # Trường hợp URL ngắn youtu.be\n",
    "        elif parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path.lstrip('/')\n",
    "                \n",
    "        # Trường hợp URL sử dụng Handle\n",
    "        elif parsed_url.path.startswith('/@'):\n",
    "            handle = parsed_url.path.split('/')[1]\n",
    "            return get_channel_id_from_handle(handle)\n",
    "                \n",
    "        return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting video ID: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_channel_id_from_handle(handle):\n",
    "    \"\"\"\n",
    "    Lấy Channel ID từ Handle bằng cách truy cập trang About và phân tích HTML.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        about_url = f\"https://www.youtube.com/{handle}/about\"\n",
    "        logger.info(f\"Truy cập trang About: {about_url}\")\n",
    "        response = requests.get(about_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Sử dụng BeautifulSoup để phân tích HTML\n",
    "        from bs4 import BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        scripts = soup.find_all('script')\n",
    "\n",
    "        for script in scripts:\n",
    "            if 'channelId' in script.text:\n",
    "                # Sử dụng regex để tìm Channel ID\n",
    "                import re\n",
    "                match = re.search(r'\"channelId\":\"(UC[A-Za-z0-9_-]{22})\"', script.text)\n",
    "                if match:\n",
    "                    channel_id = match.group(1)\n",
    "                    logger.info(f\"Channel ID tìm thấy: {channel_id}\")\n",
    "                    return channel_id\n",
    "\n",
    "        logger.error(f\"Không tìm thấy Channel ID trên trang About của handle: {handle}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Lỗi trong hàm get_channel_id_from_handle: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_video_details(video_id):\n",
    "    \"\"\"Get video details from API\"\"\"\n",
    "    url = \"https://youtube-media-downloader.p.rapidapi.com/v2/video/details\"\n",
    "    \n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": RAPID_API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"youtube-media-downloader.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    params = {\"videoId\": video_id}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"API call error for video {video_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_transcript_from_subtitles(subtitle_url, max_retries=3):\n",
    "    \"\"\"Get and process transcript from subtitles URL with retries\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            transcript_lines = []\n",
    "            subtitle_response = requests.get(subtitle_url)\n",
    "            \n",
    "            if subtitle_response.status_code == 200:\n",
    "                content = subtitle_response.content\n",
    "                if not content or len(content.strip()) == 0:\n",
    "                    raise ValueError(f\"Empty response content for URL: {subtitle_url}\")\n",
    "                \n",
    "                root = ET.fromstring(content)\n",
    "                for elem in root.iter('text'):\n",
    "                    start = elem.get('start')\n",
    "                    text = elem.text\n",
    "                    if start and text:\n",
    "                        start_seconds = float(start)\n",
    "                        start_time = str(timedelta(seconds=start_seconds))\n",
    "                        hh_mm_ss = start_time.split('.')[0]\n",
    "                        transcript_lines.append(f\"[{hh_mm_ss}] {text}\")\n",
    "                \n",
    "                if transcript_lines:\n",
    "                    transcript_text = '\\n'.join(transcript_lines)\n",
    "                    if len(transcript_text) > 95000:\n",
    "                        transcript_text = transcript_text[:95000] + \"\\n[Transcript bị cắt do quá dài]\"\n",
    "                    return transcript_text\n",
    "                    \n",
    "            else:\n",
    "                logger.warning(f\"Failed to retrieve subtitle data: {subtitle_response.status_code}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "        except (ET.ParseError, ValueError, requests.exceptions.RequestException) as e:\n",
    "            logger.warning(f\"Error processing subtitles (attempt {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "    return \"\"\n",
    "\n",
    "def get_video_comments(video_id):\n",
    "    \"\"\"Get comments for a YouTube video\"\"\"\n",
    "    try:\n",
    "        # Tạo connection\n",
    "        conn = http.client.HTTPSConnection(\"youtube-media-downloader.p.rapidapi.com\")\n",
    "        \n",
    "        # Headers chính xác như mẫu\n",
    "        headers = {\n",
    "            'X-RapidAPI-Key': RAPID_API_KEY,\n",
    "            'X-RapidAPI-Host': \"youtube-media-downloader.p.rapidapi.com\"\n",
    "        }\n",
    "        \n",
    "        all_comments = []\n",
    "        formatted_comments = []\n",
    "        next_token = None\n",
    "        \n",
    "        while True:\n",
    "            # Build URL\n",
    "            url = f\"/v2/video/comments?videoId={video_id}&sortBy=top\"\n",
    "            if next_token:\n",
    "                url += f\"&nextToken={next_token}\"\n",
    "                \n",
    "            # Make request\n",
    "            conn.request(\"GET\", url, headers=headers)\n",
    "            response = conn.getresponse()\n",
    "            data = json.loads(response.read().decode(\"utf-8\"))\n",
    "            \n",
    "            if not data.get(\"status\"):\n",
    "                error_id = data.get(\"errorId\", \"Unknown error\")\n",
    "                if error_id == \"VideoNotFoundOrCommentDisabled\":\n",
    "                    return {\n",
    "                        \"count\": 0,\n",
    "                        \"comments\": [],\n",
    "                        \"status\": \"DISABLED: Comments are disabled or video not found\"\n",
    "                    }\n",
    "                else:\n",
    "                    raise Exception(error_id)\n",
    "            \n",
    "            # Get comments from response\n",
    "            comments = data.get(\"items\", [])\n",
    "            \n",
    "            # Format comments\n",
    "            for comment in comments:\n",
    "                user_name = comment.get('channel', {}).get('name', '')\n",
    "                text = comment.get('contentText', '')\n",
    "                formatted_comment = f\"[{user_name}]\\n[{text}]\"\n",
    "                formatted_comments.append(formatted_comment)\n",
    "            \n",
    "            # Check for next page\n",
    "            next_token = data.get(\"nextToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "                \n",
    "        # Split comments if needed\n",
    "        if formatted_comments:\n",
    "            comment_parts = split_comments(formatted_comments)\n",
    "            return {\n",
    "                \"count\": len(formatted_comments),\n",
    "                \"comments\": comment_parts,\n",
    "                \"status\": f\"SUCCESS: {len(formatted_comments)} comments saved in {len(comment_parts)} parts\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"count\": 0,\n",
    "                \"comments\": [],\n",
    "                \"status\": \"NO_COMMENTS: No comments found\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting comments for video {video_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"count\": 0,\n",
    "            \"comments\": [],\n",
    "            \"status\": f\"ERROR: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def split_comments(formatted_comments, max_chars=100000):\n",
    "    \"\"\"Split comments list into smaller parts under max_chars\"\"\"\n",
    "    parts = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for comment in formatted_comments:\n",
    "        comment_length = len(comment) + 2  # Add 2 for \\n\\n between comments\n",
    "        \n",
    "        if current_length + comment_length > max_chars and current_part:\n",
    "            parts.append(\"\\n\\n\".join(current_part))\n",
    "            current_part = [comment]\n",
    "            current_length = comment_length\n",
    "        else:\n",
    "            current_part.append(comment)\n",
    "            current_length += comment_length\n",
    "    \n",
    "    if current_part:\n",
    "        parts.append(\"\\n\\n\".join(current_part))\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def convert_subscriber_count(count_text):\n",
    "    \"\"\"Convert subscriber count from text (e.g. '2.19M subscribers') to number\"\"\"\n",
    "    try:\n",
    "        if not count_text:\n",
    "            return 0\n",
    "        count = count_text.replace('subscribers', '').strip()\n",
    "        multiplier = 1\n",
    "        if 'K' in count:\n",
    "            multiplier = 1000\n",
    "            count = count.replace('K', '')\n",
    "        elif 'M' in count:\n",
    "            multiplier = 1000000\n",
    "            count = count.replace('M', '')\n",
    "        elif 'B' in count:\n",
    "            multiplier = 1000000000\n",
    "            count = count.replace('B', '')\n",
    "        return int(float(count) * multiplier)\n",
    "    except (ValueError, AttributeError):\n",
    "        logger.warning(f\"Error converting subscriber count: {count_text}\")\n",
    "        return 0\n",
    "\n",
    "def process_video_data(video_data):\n",
    "    \"\"\"Process and format video data\"\"\"\n",
    "    # Get subtitles URL safely\n",
    "    subtitles_items = video_data.get(\"subtitles\", {}).get(\"items\", [])\n",
    "    subtitles_url = subtitles_items[0].get(\"url\", \"\") if subtitles_items else \"\"\n",
    "    \n",
    "    # Get transcript if subtitles URL exists\n",
    "    transcript = \"\"\n",
    "    if subtitles_url:\n",
    "        transcript = get_transcript_from_subtitles(subtitles_url)\n",
    "    \n",
    "    # Convert subscriber count\n",
    "    subscriber_count_text = video_data.get(\"channel\", {}).get(\"subscriberCountText\", \"\")\n",
    "    subscriber_count = convert_subscriber_count(subscriber_count_text)\n",
    "    \n",
    "    # Format is_live to string\n",
    "    is_live = \"true\" if video_data.get(\"isLive\", False) else \"false\"\n",
    "    \n",
    "    # Get video ID for comments\n",
    "    video_id = video_data.get('id', '')\n",
    "    comments_data = get_video_comments(video_id)\n",
    "    \n",
    "    response = {\n",
    "        \"title\": video_data.get(\"title\", \"\"),\n",
    "        \"description\": video_data.get(\"description\", \"\"),\n",
    "        \"username\": video_data.get(\"channel\", {}).get(\"handle\", \"\"),\n",
    "        \"user_screen_name\": video_data.get(\"channel\", {}).get(\"name\", \"\"),\n",
    "        \"user_id\": video_data.get(\"channel\", {}).get(\"id\", \"\"),\n",
    "        \"user_subscribers\": subscriber_count,\n",
    "        \"published_time\": video_data.get(\"publishedTime\", \"\"),\n",
    "        \"viewCount\": video_data.get(\"viewCount\", 0),\n",
    "        \"likeCount\": video_data.get(\"likeCount\", 0),\n",
    "        \"subtitles_url\": subtitles_url,\n",
    "        \"duration\": video_data.get(\"duration\", \"\"),\n",
    "        \"thumbnail_url\": video_data.get(\"thumbnail\", [{}])[0].get(\"url\", \"\"),\n",
    "        \"is_live\": is_live,\n",
    "        \"category\": video_data.get(\"category\", \"\"),\n",
    "        \"transcript\": transcript,\n",
    "        \"url\": f\"https://youtube.com/watch?v={video_data.get('id', '')}\",\n",
    "        \"comments_count\": comments_data[\"count\"],\n",
    "        \"comments_status\": comments_data[\"status\"]\n",
    "    }\n",
    "    \n",
    "    # Add comments parts if they exist\n",
    "    if comments_data[\"comments\"]:\n",
    "        for i, part in enumerate(comments_data[\"comments\"], 1):\n",
    "            response[f\"comments_{i}\"] = part\n",
    "            \n",
    "    return response\n",
    "\n",
    "def process_single_video(youtube_url):\n",
    "    \"\"\"Process a single YouTube video and return formatted data\"\"\"\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    if not video_id:\n",
    "        logger.error(f\"Invalid YouTube URL: {youtube_url}\")\n",
    "        return {\"error\": \"Invalid YouTube URL\", \"url\": youtube_url}\n",
    "    \n",
    "    video_data = get_video_details(video_id)\n",
    "    if not video_data:\n",
    "        logger.error(f\"Failed to fetch video details for video ID: {video_id}\")\n",
    "        return {\"error\": \"Failed to fetch video details\", \"url\": youtube_url}\n",
    "    \n",
    "    formatted_data = process_video_data(video_data)\n",
    "    formatted_data[\"url_provided\"] = youtube_url\n",
    "    return formatted_data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process a list of YouTube URLs\"\"\"\n",
    "    # Danh sách các URL YouTube bạn muốn xử lý\n",
    "    youtube_urls = [\n",
    "        \"https://www.youtube.com/watch?v=VIDEO_ID_1\",\n",
    "        \"https://www.youtube.com/watch?v=VIDEO_ID_2\",\n",
    "        \"https://youtu.be/VIDEO_ID_3\",\n",
    "        \"https://www.youtube.com/@moxierobot\",\n",
    "        # Thêm các URL khác ở đây\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    max_workers = 5  # Số lượng luồng song song\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_url = {executor.submit(process_single_video, url): url for url in youtube_urls}\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                results.append(data)\n",
    "                logger.info(f\"Đã xử lý xong video: {url}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Lỗi khi xử lý video {url}: {str(e)}\")\n",
    "                results.append({\"error\": str(e), \"url\": url})\n",
    "\n",
    "    # Lưu kết quả vào file JSON\n",
    "    with open('batch_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    logger.info(\"Đã lưu kết quả vào 'batch_results.json'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "#### **2. Giải Thích Script:**\n",
    "\n",
    "- **ThreadPoolExecutor**: Sử dụng để xử lý nhiều video song song, giúp tăng tốc quá trình xử lý.\n",
    "  \n",
    "- **Danh sách URL YouTube**: Bạn có thể thêm nhiều URL YouTube vào danh sách `youtube_urls` để xử lý hàng loạt.\n",
    "\n",
    "- **Xử lý Handle**: Hàm `extract_video_id` đã được mở rộng để xử lý các URL sử dụng Handle (ví dụ: `https://www.youtube.com/@moxierobot`).\n",
    "\n",
    "- **Xử lý Transcript và Comments**: Script sẽ lấy transcript và comments cho từng video, xử lý và lưu trữ chúng.\n",
    "\n",
    "- **Lưu kết quả**: Kết quả được lưu vào file `batch_results.json`.\n",
    "\n",
    "#### **3. Chạy Script:**\n",
    "\n",
    "```bash\n",
    "python batch_script.py\n",
    "```\n",
    "\n",
    "#### **4. Lưu Ý:**\n",
    "\n",
    "- **API Key Bảo Mật**: Đảm bảo rằng file `.env` chứa biến `RAPID_API_KEY` không được đẩy lên các kho mã nguồn công khai.\n",
    "\n",
    "- **Giới hạn Tỷ lệ Yêu cầu**: Mặc dù bạn không phải lo lắng về giới hạn tỷ lệ của API như khi sử dụng API từ bên ngoài, nhưng vẫn nên kiểm soát số lượng yêu cầu song song để tránh quá tải hệ thống hoặc API.\n",
    "\n",
    "- **Xử lý Lỗi**: Script đã bao gồm cơ chế xử lý lỗi cơ bản, nhưng bạn có thể mở rộng thêm để xử lý các trường hợp phức tạp hơn.\n",
    "\n",
    "---\n",
    "\n",
    "## **So Sánh Hai Phương Pháp**\n",
    "\n",
    "| Tiêu chí                  | Sử dụng API Hiện Tại                  | Chuyển Đổi Sang Script Cục Bộ          |\n",
    "|---------------------------|---------------------------------------|----------------------------------------|\n",
    "| **Tốc độ và Hiệu suất**   | Trung bình (tuỳ thuộc vào số lượng yêu cầu và tốc độ mạng) | Cao hơn (xử lý trực tiếp cục bộ)        |\n",
    "| **Quản lý Tỷ lệ Yêu cầu** | Phụ thuộc vào giới hạn API             | Không bị giới hạn bởi API               |\n",
    "| **Bảo mật**               | Tốt (sử dụng API Key)                  | Kém hơn nếu không quản lý API Key tốt   |\n",
    "| **Khả năng Mở rộng**      | Cao (dễ dàng triển khai trên cloud)    | Trung bình (phụ thuộc vào tài nguyên hệ thống) |\n",
    "| **Độ phức tạp**           | Phức tạp hơn trong việc gửi nhiều yêu cầu | Đơn giản hơn khi xử lý cục bộ          |\n",
    "| **Tính linh hoạt**        | Cao (dễ dàng tích hợp vào các ứng dụng khác) | Trung bình (chỉ xử lý cục bộ)           |\n",
    "\n",
    "---\n",
    "\n",
    "## **Kết Luận và Khuyến Nghị**\n",
    "\n",
    "- **Nếu bạn cần tích hợp xử lý video vào các ứng dụng web hoặc dịch vụ khác**, việc sử dụng API hiện tại để xử lý hàng loạt thông qua nhiều yêu cầu song song là phù hợp hơn. Bạn có thể tối ưu hóa script `batch_process.py` để gửi nhiều yêu cầu một cách hiệu quả.\n",
    "\n",
    "- **Nếu bạn chủ yếu xử lý video hàng loạt một cách cục bộ**, việc chuyển đổi API thành một script riêng biệt như `batch_script.py` sẽ mang lại hiệu suất cao hơn và quản lý dễ dàng hơn.\n",
    "\n",
    "Dưới đây là một số gợi ý bổ sung để tối ưu hóa quá trình xử lý:\n",
    "\n",
    "### **1. Sử Dụng Asynchronous Requests**\n",
    "\n",
    "Thay vì sử dụng `ThreadPoolExecutor`, bạn có thể sử dụng các thư viện như `aiohttp` và `asyncio` để xử lý các yêu cầu một cách không đồng bộ, giúp tăng hiệu suất hơn nữa.\n",
    "\n",
    "#### **Ví Dụ với `aiohttp`:**\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import timedelta\n",
    "\n",
    "# Tải biến môi trường từ file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Có thể thay đổi thành logging.DEBUG để xem chi tiết hơn\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Rapid API key từ environment variable \n",
    "RAPID_API_KEY = os.environ.get('RAPID_API_KEY')\n",
    "if not RAPID_API_KEY:\n",
    "    logger.error(\"RAPID_API_KEY not found in environment variables\")\n",
    "    raise ValueError(\"Missing RAPID_API_KEY in environment\")\n",
    "\n",
    "logger.info(f\"RAPID_API_KEY loaded: {RAPID_API_KEY[:5]}...\")  # Log 5 ký tự đầu để kiểm tra\n",
    "\n",
    "async def fetch(session, url, headers=None, params=None):\n",
    "    \"\"\"Fetch data từ một URL sử dụng aiohttp\"\"\"\n",
    "    async with session.get(url, headers=headers, params=params) as response:\n",
    "        response.raise_for_status()\n",
    "        return await response.json()\n",
    "\n",
    "async def process_video(session, youtube_url):\n",
    "    \"\"\"Xử lý một video YouTube\"\"\"\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    if not video_id:\n",
    "        logger.error(f\"Invalid YouTube URL: {youtube_url}\")\n",
    "        return {\"error\": \"Invalid YouTube URL\", \"url\": youtube_url}\n",
    "    \n",
    "    # Get video details\n",
    "    try:\n",
    "        video_data = await get_video_details_async(session, video_id)\n",
    "        if not video_data:\n",
    "            logger.error(f\"Failed to fetch video details for video ID: {video_id}\")\n",
    "            return {\"error\": \"Failed to fetch video details\", \"url\": youtube_url}\n",
    "        \n",
    "        # Process video data\n",
    "        formatted_data = process_video_data(video_data)\n",
    "        formatted_data[\"url_provided\"] = youtube_url\n",
    "        return formatted_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing video {youtube_url}: {str(e)}\")\n",
    "        return {\"error\": str(e), \"url\": youtube_url}\n",
    "\n",
    "def extract_video_id(youtube_url):\n",
    "    \"\"\"Extract video ID từ URL YouTube\"\"\"\n",
    "    try:\n",
    "        # Thêm https:// nếu URL không có\n",
    "        if not youtube_url.startswith(('http://', 'https://')):\n",
    "            youtube_url = 'https://' + youtube_url\n",
    "                \n",
    "        parsed_url = urlparse(youtube_url)\n",
    "            \n",
    "        # Kiểm tra hostname hợp lệ\n",
    "        if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
    "            if parsed_url.path == '/watch':\n",
    "                return parse_qs(parsed_url.query)['v'][0]\n",
    "            elif parsed_url.path.startswith('/embed/'):\n",
    "                return parsed_url.path.split('/')[2]\n",
    "            elif parsed_url.path.startswith('/v/'):\n",
    "                return parsed_url.path.split('/')[2]\n",
    "                    \n",
    "        # Trường hợp URL ngắn youtu.be\n",
    "        elif parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path.lstrip('/')\n",
    "                \n",
    "        # Trường hợp URL sử dụng Handle\n",
    "        elif parsed_url.path.startswith('/@'):\n",
    "            handle = parsed_url.path.split('/')[1]\n",
    "            return get_channel_id_from_handle(handle)\n",
    "                \n",
    "        return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting video ID: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_channel_id_from_handle(handle):\n",
    "    \"\"\"\n",
    "    Lấy Channel ID từ Handle bằng cách truy cập trang About và phân tích HTML.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        about_url = f\"https://www.youtube.com/{handle}/about\"\n",
    "        logger.info(f\"Truy cập trang About: {about_url}\")\n",
    "        response = requests.get(about_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Sử dụng BeautifulSoup để phân tích HTML\n",
    "        from bs4 import BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        scripts = soup.find_all('script')\n",
    "\n",
    "        for script in scripts:\n",
    "            if 'channelId' in script.text:\n",
    "                # Sử dụng regex để tìm Channel ID\n",
    "                import re\n",
    "                match = re.search(r'\"channelId\":\"(UC[A-Za-z0-9_-]{22})\"', script.text)\n",
    "                if match:\n",
    "                    channel_id = match.group(1)\n",
    "                    logger.info(f\"Channel ID tìm thấy: {channel_id}\")\n",
    "                    return channel_id\n",
    "\n",
    "        logger.error(f\"Không tìm thấy Channel ID trên trang About của handle: {handle}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Lỗi trong hàm get_channel_id_from_handle: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "async def get_video_details_async(session, video_id):\n",
    "    \"\"\"Get video details từ API sử dụng aiohttp\"\"\"\n",
    "    url = \"https://youtube-media-downloader.p.rapidapi.com/v2/video/details\"\n",
    "    \n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": RAPID_API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"youtube-media-downloader.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    params = {\"videoId\": video_id}\n",
    "    \n",
    "    try:\n",
    "        video_data = await fetch(session, url, headers=headers, params=params)\n",
    "        return video_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"API call error for video {video_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def convert_subscriber_count(count_text):\n",
    "    \"\"\"Convert subscriber count từ text (ví dụ: '2.19M subscribers') thành số\"\"\"\n",
    "    try:\n",
    "        if not count_text:\n",
    "            return 0\n",
    "        count = count_text.replace('subscribers', '').strip()\n",
    "        multiplier = 1\n",
    "        if 'K' in count:\n",
    "            multiplier = 1000\n",
    "            count = count.replace('K', '')\n",
    "        elif 'M' in count:\n",
    "            multiplier = 1000000\n",
    "            count = count.replace('M', '')\n",
    "        elif 'B' in count:\n",
    "            multiplier = 1000000000\n",
    "            count = count.replace('B', '')\n",
    "        return int(float(count) * multiplier)\n",
    "    except (ValueError, AttributeError):\n",
    "        logger.warning(f\"Error converting subscriber count: {count_text}\")\n",
    "        return 0\n",
    "\n",
    "def get_transcript_from_subtitles(subtitle_url, max_retries=3):\n",
    "    \"\"\"Get và xử lý transcript từ URL subtitles với retries\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            transcript_lines = []\n",
    "            subtitle_response = requests.get(subtitle_url)\n",
    "            \n",
    "            if subtitle_response.status_code == 200:\n",
    "                content = subtitle_response.content\n",
    "                if not content or len(content.strip()) == 0:\n",
    "                    raise ValueError(f\"Empty response content for URL: {subtitle_url}\")\n",
    "                \n",
    "                root = ET.fromstring(content)\n",
    "                for elem in root.iter('text'):\n",
    "                    start = elem.get('start')\n",
    "                    text = elem.text\n",
    "                    if start and text:\n",
    "                        start_seconds = float(start)\n",
    "                        start_time = str(timedelta(seconds=start_seconds))\n",
    "                        hh_mm_ss = start_time.split('.')[0]\n",
    "                        transcript_lines.append(f\"[{hh_mm_ss}] {text}\")\n",
    "                \n",
    "                if transcript_lines:\n",
    "                    transcript_text = '\\n'.join(transcript_lines)\n",
    "                    if len(transcript_text) > 95000:\n",
    "                        transcript_text = transcript_text[:95000] + \"\\n[Transcript bị cắt do quá dài]\"\n",
    "                    return transcript_text\n",
    "                    \n",
    "            else:\n",
    "                logger.warning(f\"Failed to retrieve subtitle data: {subtitle_response.status_code}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "        except (ET.ParseError, ValueError, requests.exceptions.RequestException) as e:\n",
    "            logger.warning(f\"Error processing subtitles (attempt {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "    return \"\"\n",
    "\n",
    "def get_video_comments(video_id):\n",
    "    \"\"\"Get comments cho một video YouTube\"\"\"\n",
    "    try:\n",
    "        # Tạo connection\n",
    "        conn = http.client.HTTPSConnection(\"youtube-media-downloader.p.rapidapi.com\")\n",
    "        \n",
    "        # Headers chính xác như mẫu\n",
    "        headers = {\n",
    "            'X-RapidAPI-Key': RAPID_API_KEY,\n",
    "            'X-RapidAPI-Host': \"youtube-media-downloader.p.rapidapi.com\"\n",
    "        }\n",
    "        \n",
    "        all_comments = []\n",
    "        formatted_comments = []\n",
    "        next_token = None\n",
    "        \n",
    "        while True:\n",
    "            # Build URL\n",
    "            url = f\"/v2/video/comments?videoId={video_id}&sortBy=top\"\n",
    "            if next_token:\n",
    "                url += f\"&nextToken={next_token}\"\n",
    "                \n",
    "            # Make request\n",
    "            conn.request(\"GET\", url, headers=headers)\n",
    "            response = conn.getresponse()\n",
    "            data = json.loads(response.read().decode(\"utf-8\"))\n",
    "            \n",
    "            if not data.get(\"status\"):\n",
    "                error_id = data.get(\"errorId\", \"Unknown error\")\n",
    "                if error_id == \"VideoNotFoundOrCommentDisabled\":\n",
    "                    return {\n",
    "                        \"count\": 0,\n",
    "                        \"comments\": [],\n",
    "                        \"status\": \"DISABLED: Comments are disabled or video not found\"\n",
    "                    }\n",
    "                else:\n",
    "                    raise Exception(error_id)\n",
    "            \n",
    "            # Get comments from response\n",
    "            comments = data.get(\"items\", [])\n",
    "            \n",
    "            # Format comments\n",
    "            for comment in comments:\n",
    "                user_name = comment.get('channel', {}).get('name', '')\n",
    "                text = comment.get('contentText', '')\n",
    "                formatted_comment = f\"[{user_name}]\\n[{text}]\"\n",
    "                formatted_comments.append(formatted_comment)\n",
    "            \n",
    "            # Check for next page\n",
    "            next_token = data.get(\"nextToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "                \n",
    "        # Split comments if needed\n",
    "        if formatted_comments:\n",
    "            comment_parts = split_comments(formatted_comments)\n",
    "            return {\n",
    "                \"count\": len(formatted_comments),\n",
    "                \"comments\": comment_parts,\n",
    "                \"status\": f\"SUCCESS: {len(formatted_comments)} comments saved in {len(comment_parts)} parts\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"count\": 0,\n",
    "                \"comments\": [],\n",
    "                \"status\": \"NO_COMMENTS: No comments found\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting comments for video {video_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"count\": 0,\n",
    "            \"comments\": [],\n",
    "            \"status\": f\"ERROR: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def split_comments(formatted_comments, max_chars=100000):\n",
    "    \"\"\"Split comments list into smaller parts dưới max_chars\"\"\"\n",
    "    parts = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for comment in formatted_comments:\n",
    "        comment_length = len(comment) + 2  # Thêm 2 cho \\n\\n giữa các comments\n",
    "        \n",
    "        if current_length + comment_length > max_chars and current_part:\n",
    "            parts.append(\"\\n\\n\".join(current_part))\n",
    "            current_part = [comment]\n",
    "            current_length = comment_length\n",
    "        else:\n",
    "            current_part.append(comment)\n",
    "            current_length += comment_length\n",
    "    \n",
    "    if current_part:\n",
    "        parts.append(\"\\n\\n\".join(current_part))\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def process_video_data(video_data):\n",
    "    \"\"\"Process và format video data\"\"\"\n",
    "    # Get subtitles URL safely\n",
    "    subtitles_items = video_data.get(\"subtitles\", {}).get(\"items\", [])\n",
    "    subtitles_url = subtitles_items[0].get(\"url\", \"\") if subtitles_items else \"\"\n",
    "    \n",
    "    # Get transcript nếu có subtitles URL\n",
    "    transcript = \"\"\n",
    "    if subtitles_url:\n",
    "        transcript = get_transcript_from_subtitles(subtitles_url)\n",
    "    \n",
    "    # Convert subscriber count\n",
    "    subscriber_count_text = video_data.get(\"channel\", {}).get(\"subscriberCountText\", \"\")\n",
    "    subscriber_count = convert_subscriber_count(subscriber_count_text)\n",
    "    \n",
    "    # Format is_live to string\n",
    "    is_live = \"true\" if video_data.get(\"isLive\", False) else \"false\"\n",
    "    \n",
    "    # Get video ID for comments\n",
    "    video_id = video_data.get('id', '')\n",
    "    comments_data = get_video_comments(video_id)\n",
    "    \n",
    "    response = {\n",
    "        \"title\": video_data.get(\"title\", \"\"),\n",
    "        \"description\": video_data.get(\"description\", \"\"),\n",
    "        \"username\": video_data.get(\"channel\", {}).get(\"handle\", \"\"),\n",
    "        \"user_screen_name\": video_data.get(\"channel\", {}).get(\"name\", \"\"),\n",
    "        \"user_id\": video_data.get(\"channel\", {}).get(\"id\", \"\"),\n",
    "        \"user_subscribers\": subscriber_count,\n",
    "        \"published_time\": video_data.get(\"publishedTime\", \"\"),\n",
    "        \"viewCount\": video_data.get(\"viewCount\", 0),\n",
    "        \"likeCount\": video_data.get(\"likeCount\", 0),\n",
    "        \"subtitles_url\": subtitles_url,\n",
    "        \"duration\": video_data.get(\"duration\", \"\"),\n",
    "        \"thumbnail_url\": video_data.get(\"thumbnail\", [{}])[0].get(\"url\", \"\"),\n",
    "        \"is_live\": is_live,\n",
    "        \"category\": video_data.get(\"category\", \"\"),\n",
    "        \"transcript\": transcript,\n",
    "        \"url\": f\"https://youtube.com/watch?v={video_data.get('id', '')}\",\n",
    "        \"comments_count\": comments_data[\"count\"],\n",
    "        \"comments_status\": comments_data[\"status\"]\n",
    "    }\n",
    "    \n",
    "    # Thêm comments parts nếu có\n",
    "    if comments_data[\"comments\"]:\n",
    "        for i, part in enumerate(comments_data[\"comments\"], 1):\n",
    "            response[f\"comments_{i}\"] = part\n",
    "            \n",
    "    return response\n",
    "\n",
    "async def get_transcript_from_subtitles_async(session, subtitle_url, max_retries=3):\n",
    "    \"\"\"Get và xử lý transcript từ subtitles URL với retries (async)\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            transcript_lines = []\n",
    "            async with session.get(subtitle_url) as subtitle_response:\n",
    "                if subtitle_response.status == 200:\n",
    "                    content = await subtitle_response.text()\n",
    "                    if not content or len(content.strip()) == 0:\n",
    "                        raise ValueError(f\"Empty response content for URL: {subtitle_url}\")\n",
    "                    \n",
    "                    root = ET.fromstring(content)\n",
    "                    for elem in root.iter('text'):\n",
    "                        start = elem.get('start')\n",
    "                        text = elem.text\n",
    "                        if start and text:\n",
    "                            start_seconds = float(start)\n",
    "                            start_time = str(timedelta(seconds=start_seconds))\n",
    "                            hh_mm_ss = start_time.split('.')[0]\n",
    "                            transcript_lines.append(f\"[{hh_mm_ss}] {text}\")\n",
    "                    \n",
    "                    if transcript_lines:\n",
    "                        transcript_text = '\\n'.join(transcript_lines)\n",
    "                        if len(transcript_text) > 95000:\n",
    "                            transcript_text = transcript_text[:95000] + \"\\n[Transcript bị cắt do quá dài]\"\n",
    "                        return transcript_text\n",
    "                    \n",
    "                else:\n",
    "                    logger.warning(f\"Failed to retrieve subtitle data: {subtitle_response.status}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        await asyncio.sleep(2)\n",
    "                    continue\n",
    "                    \n",
    "        except (ET.ParseError, ValueError, aiohttp.ClientError) as e:\n",
    "            logger.warning(f\"Error processing subtitles (attempt {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                await asyncio.sleep(2)\n",
    "            continue\n",
    "                \n",
    "    return \"\"\n",
    "\n",
    "def convert_subscriber_count(count_text):\n",
    "    \"\"\"Convert subscriber count từ text (ví dụ: '2.19M subscribers') thành số\"\"\"\n",
    "    try:\n",
    "        if not count_text:\n",
    "            return 0\n",
    "        count = count_text.replace('subscribers', '').strip()\n",
    "        multiplier = 1\n",
    "        if 'K' in count:\n",
    "            multiplier = 1000\n",
    "            count = count.replace('K', '')\n",
    "        elif 'M' in count:\n",
    "            multiplier = 1000000\n",
    "            count = count.replace('M', '')\n",
    "        elif 'B' in count:\n",
    "            multiplier = 1000000000\n",
    "            count = count.replace('B', '')\n",
    "        return int(float(count) * multiplier)\n",
    "    except (ValueError, AttributeError):\n",
    "        logger.warning(f\"Error converting subscriber count: {count_text}\")\n",
    "        return 0\n",
    "\n",
    "async def get_video_comments_async(session, video_id):\n",
    "    \"\"\"Get comments cho một video YouTube sử dụng aiohttp\"\"\"\n",
    "    try:\n",
    "        url = f\"https://youtube-media-downloader.p.rapidapi.com/v2/video/comments?videoId={video_id}&sortBy=top\"\n",
    "        headers = {\n",
    "            'X-RapidAPI-Key': RAPID_API_KEY,\n",
    "            'X-RapidAPI-Host': \"youtube-media-downloader.p.rapidapi.com\"\n",
    "        }\n",
    "        \n",
    "        all_comments = []\n",
    "        formatted_comments = []\n",
    "        next_token = None\n",
    "        \n",
    "        while True:\n",
    "            # Thêm nextToken nếu có\n",
    "            params = {}\n",
    "            if next_token:\n",
    "                params[\"nextToken\"] = next_token\n",
    "                \n",
    "            # Gửi yêu cầu\n",
    "            data = await fetch(session, url, headers=headers, params=params)\n",
    "            \n",
    "            if not data.get(\"status\"):\n",
    "                error_id = data.get(\"errorId\", \"Unknown error\")\n",
    "                if error_id == \"VideoNotFoundOrCommentDisabled\":\n",
    "                    return {\n",
    "                        \"count\": 0,\n",
    "                        \"comments\": [],\n",
    "                        \"status\": \"DISABLED: Comments are disabled or video not found\"\n",
    "                    }\n",
    "                else:\n",
    "                    raise Exception(error_id)\n",
    "            \n",
    "            # Lấy comments từ phản hồi\n",
    "            comments = data.get(\"items\", [])\n",
    "            \n",
    "            # Định dạng comments\n",
    "            for comment in comments:\n",
    "                user_name = comment.get('channel', {}).get('name', '')\n",
    "                text = comment.get('contentText', '')\n",
    "                formatted_comment = f\"[{user_name}]\\n[{text}]\"\n",
    "                formatted_comments.append(formatted_comment)\n",
    "            \n",
    "            # Kiểm tra next page\n",
    "            next_token = data.get(\"nextToken\")\n",
    "            if not next_token:\n",
    "                break\n",
    "                \n",
    "        # Split comments nếu cần\n",
    "        if formatted_comments:\n",
    "            comment_parts = split_comments(formatted_comments)\n",
    "            return {\n",
    "                \"count\": len(formatted_comments),\n",
    "                \"comments\": comment_parts,\n",
    "                \"status\": f\"SUCCESS: {len(formatted_comments)} comments saved in {len(comment_parts)} parts\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"count\": 0,\n",
    "                \"comments\": [],\n",
    "                \"status\": \"NO_COMMENTS: No comments found\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting comments for video {video_id}: {str(e)}\")\n",
    "        return {\n",
    "            \"count\": 0,\n",
    "            \"comments\": [],\n",
    "            \"status\": f\"ERROR: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def split_comments(formatted_comments, max_chars=100000):\n",
    "    \"\"\"Split comments list into smaller parts dưới max_chars\"\"\"\n",
    "    parts = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for comment in formatted_comments:\n",
    "        comment_length = len(comment) + 2  # Thêm 2 cho \\n\\n giữa các comments\n",
    "        \n",
    "        if current_length + comment_length > max_chars and current_part:\n",
    "            parts.append(\"\\n\\n\".join(current_part))\n",
    "            current_part = [comment]\n",
    "            current_length = comment_length\n",
    "        else:\n",
    "            current_part.append(comment)\n",
    "            current_length += comment_length\n",
    "    \n",
    "    if current_part:\n",
    "        parts.append(\"\\n\\n\".join(current_part))\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def get_transcript_from_subtitles(subtitle_url, max_retries=3):\n",
    "    \"\"\"Get và xử lý transcript từ subtitles URL với retries\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            transcript_lines = []\n",
    "            subtitle_response = requests.get(subtitle_url)\n",
    "            \n",
    "            if subtitle_response.status_code == 200:\n",
    "                content = subtitle_response.content\n",
    "                if not content or len(content.strip()) == 0:\n",
    "                    raise ValueError(f\"Empty response content for URL: {subtitle_url}\")\n",
    "                \n",
    "                root = ET.fromstring(content)\n",
    "                for elem in root.iter('text'):\n",
    "                    start = elem.get('start')\n",
    "                    text = elem.text\n",
    "                    if start and text:\n",
    "                        start_seconds = float(start)\n",
    "                        start_time = str(timedelta(seconds=start_seconds))\n",
    "                        hh_mm_ss = start_time.split('.')[0]\n",
    "                        transcript_lines.append(f\"[{hh_mm_ss}] {text}\")\n",
    "                \n",
    "                if transcript_lines:\n",
    "                    transcript_text = '\\n'.join(transcript_lines)\n",
    "                    if len(transcript_text) > 95000:\n",
    "                        transcript_text = transcript_text[:95000] + \"\\n[Transcript bị cắt do quá dài]\"\n",
    "                    return transcript_text\n",
    "                    \n",
    "            else:\n",
    "                logger.warning(f\"Failed to retrieve subtitle data: {subtitle_response.status_code}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2)\n",
    "                continue\n",
    "                \n",
    "        except (ET.ParseError, ValueError, requests.exceptions.RequestException) as e:\n",
    "            logger.warning(f\"Error processing subtitles (attempt {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "    return \"\"\n",
    "\n",
    "def convert_subscriber_count(count_text):\n",
    "    \"\"\"Convert subscriber count từ text (ví dụ: '2.19M subscribers') thành số\"\"\"\n",
    "    try:\n",
    "        if not count_text:\n",
    "            return 0\n",
    "        count = count_text.replace('subscribers', '').strip()\n",
    "        multiplier = 1\n",
    "        if 'K' in count:\n",
    "            multiplier = 1000\n",
    "            count = count.replace('K', '')\n",
    "        elif 'M' in count:\n",
    "            multiplier = 1000000\n",
    "            count = count.replace('M', '')\n",
    "        elif 'B' in count:\n",
    "            multiplier = 1000000000\n",
    "            count = count.replace('B', '')\n",
    "        return int(float(count) * multiplier)\n",
    "    except (ValueError, AttributeError):\n",
    "        logger.warning(f\"Error converting subscriber count: {count_text}\")\n",
    "        return 0\n",
    "\n",
    "def process_video_data(video_data):\n",
    "    \"\"\"Process và format video data\"\"\"\n",
    "    # Get subtitles URL safely\n",
    "    subtitles_items = video_data.get(\"subtitles\", {}).get(\"items\", [])\n",
    "    subtitles_url = subtitles_items[0].get(\"url\", \"\") if subtitles_items else \"\"\n",
    "    \n",
    "    # Get transcript nếu có subtitles URL\n",
    "    transcript = \"\"\n",
    "    if subtitles_url:\n",
    "        transcript = get_transcript_from_subtitles(subtitles_url)\n",
    "    \n",
    "    # Convert subscriber count\n",
    "    subscriber_count_text = video_data.get(\"channel\", {}).get(\"subscriberCountText\", \"\")\n",
    "    subscriber_count = convert_subscriber_count(subscriber_count_text)\n",
    "    \n",
    "    # Format is_live to string\n",
    "    is_live = \"true\" if video_data.get(\"isLive\", False) else \"false\"\n",
    "    \n",
    "    # Get video ID for comments\n",
    "    video_id = video_data.get('id', '')\n",
    "    comments_data = get_video_comments(video_id)\n",
    "    \n",
    "    response = {\n",
    "        \"title\": video_data.get(\"title\", \"\"),\n",
    "        \"description\": video_data.get(\"description\", \"\"),\n",
    "        \"username\": video_data.get(\"channel\", {}).get(\"handle\", \"\"),\n",
    "        \"user_screen_name\": video_data.get(\"channel\", {}).get(\"name\", \"\"),\n",
    "        \"user_id\": video_data.get(\"channel\", {}).get(\"id\", \"\"),\n",
    "        \"user_subscribers\": subscriber_count,\n",
    "        \"published_time\": video_data.get(\"publishedTime\", \"\"),\n",
    "        \"viewCount\": video_data.get(\"viewCount\", 0),\n",
    "        \"likeCount\": video_data.get(\"likeCount\", 0),\n",
    "        \"subtitles_url\": subtitles_url,\n",
    "        \"duration\": video_data.get(\"duration\", \"\"),\n",
    "        \"thumbnail_url\": video_data.get(\"thumbnail\", [{}])[0].get(\"url\", \"\"),\n",
    "        \"is_live\": is_live,\n",
    "        \"category\": video_data.get(\"category\", \"\"),\n",
    "        \"transcript\": transcript,\n",
    "        \"url\": f\"https://youtube.com/watch?v={video_data.get('id', '')}\",\n",
    "        \"comments_count\": comments_data[\"count\"],\n",
    "        \"comments_status\": comments_data[\"status\"]\n",
    "    }\n",
    "    \n",
    "    # Thêm comments parts nếu có\n",
    "    if comments_data[\"comments\"]:\n",
    "        for i, part in enumerate(comments_data[\"comments\"], 1):\n",
    "            response[f\"comments_{i}\"] = part\n",
    "            \n",
    "    return response\n",
    "\n",
    "async def get_video_details_async(session, video_id):\n",
    "    \"\"\"Get video details từ API sử dụng aiohttp\"\"\"\n",
    "    url = \"https://youtube-media-downloader.p.rapidapi.com/v2/video/details\"\n",
    "    \n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": RAPID_API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"youtube-media-downloader.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    params = {\"videoId\": video_id}\n",
    "    \n",
    "    try:\n",
    "        video_data = await fetch(session, url, headers=headers, params=params)\n",
    "        return video_data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"API call error for video {video_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to process a list of YouTube URLs\"\"\"\n",
    "    # Danh sách các URL YouTube bạn muốn xử lý\n",
    "    youtube_urls = [\n",
    "        \"https://www.youtube.com/watch?v=VIDEO_ID_1\",\n",
    "        \"https://www.youtube.com/watch?v=VIDEO_ID_2\",\n",
    "        \"https://youtu.be/VIDEO_ID_3\",\n",
    "        \"https://www.youtube.com/@moxierobot\",\n",
    "        # Thêm các URL khác ở đây\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    max_workers = 10  # Số lượng kết nối đồng thời\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in youtube_urls:\n",
    "            tasks.append(process_video(session, url))\n",
    "        \n",
    "        # Chạy các task không đồng bộ\n",
    "        for future in asyncio.as_completed(tasks):\n",
    "            result = await future\n",
    "            results.append(result)\n",
    "            logger.info(f\"Processed video: {result.get('url_provided', 'Unknown')}\")\n",
    "    \n",
    "    # Lưu kết quả vào file JSON\n",
    "    with open('batch_results_async.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    logger.info(\"Đã lưu kết quả vào 'batch_results_async.json'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "```\n",
    "\n",
    "#### **2. Giải Thích Script:**\n",
    "\n",
    "- **Asynchronous Requests (`aiohttp` và `asyncio`)**: Sử dụng để gửi nhiều yêu cầu một cách không đồng bộ, giúp tăng hiệu suất xử lý hàng loạt.\n",
    "\n",
    "- **Hàm `fetch`**: Truy vấn bất kỳ URL nào và trả về dữ liệu JSON.\n",
    "\n",
    "- **Hàm `process_video`**: Xử lý một video YouTube, bao gồm trích xuất ID, lấy chi tiết video, transcript và comments.\n",
    "\n",
    "- **Hàm `main`**: Tạo các task để xử lý các video cùng lúc và thu thập kết quả.\n",
    "\n",
    "#### **3. Cài Đặt Thư Viện Cần Thiết:**\n",
    "\n",
    "Đảm bảo rằng bạn đã cài đặt các thư viện cần thiết:\n",
    "\n",
    "```bash\n",
    "pip install aiohttp beautifulsoup4 python-dotenv\n",
    "```\n",
    "\n",
    "#### **4. Chạy Script:**\n",
    "\n",
    "```bash\n",
    "python batch_script_async.py\n",
    "```\n",
    "\n",
    "#### **5. Lưu Ý:**\n",
    "\n",
    "- **Giới hạn Tỷ lệ Yêu cầu**: Mặc dù bạn sử dụng async, hãy kiểm soát số lượng kết nối đồng thời (`max_workers`) để tránh quá tải API hoặc hệ thống.\n",
    "\n",
    "- **Xử lý Lỗi**: Script đã bao gồm cơ chế xử lý lỗi cơ bản. Bạn có thể mở rộng thêm để xử lý các trường hợp phức tạp hơn.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tóm Tắt và Khuyến Nghị**\n",
    "\n",
    "- **Nếu bạn cần xử lý một lượng video lớn một cách thường xuyên và muốn tăng hiệu suất**, chuyển đổi API sang một script cục bộ sử dụng `ThreadPoolExecutor` hoặc `asyncio` là lựa chọn tốt hơn.\n",
    "\n",
    "- **Nếu bạn muốn duy trì tính linh hoạt và mở rộng để tích hợp vào các ứng dụng khác**, sử dụng API hiện tại với các cải tiến như xử lý song song thông qua nhiều yêu cầu HTTP là phù hợp hơn.\n",
    "\n",
    "- **Xem xét bảo mật và quản lý API Key**: Nếu bạn chuyển đổi sang script cục bộ, đảm bảo rằng API Key được bảo mật tốt và không bị lộ ra ngoài.\n",
    "\n",
    "- **Kiểm soát tài nguyên hệ thống**: Khi xử lý hàng loạt video, hãy đảm bảo rằng hệ thống của bạn có đủ tài nguyên (CPU, RAM) để xử lý đồng thời mà không gặp vấn đề về hiệu suất.\n",
    "\n",
    "- **Xử lý và lưu trữ kết quả**: Dù chọn phương pháp nào, hãy đảm bảo rằng bạn có cơ chế lưu trữ và quản lý kết quả một cách hiệu quả, ví dụ như lưu vào file JSON hoặc cơ sở dữ liệu.\n",
    "\n",
    "Nếu bạn cần thêm hỗ trợ hoặc gặp phải vấn đề cụ thể nào trong quá trình triển khai, đừng ngần ngại chia sẻ thêm thông tin để mình có thể giúp đỡ bạn một cách chi tiết hơn.\n",
    "\n",
    "Chúc bạn thành công với dự án của mình!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
