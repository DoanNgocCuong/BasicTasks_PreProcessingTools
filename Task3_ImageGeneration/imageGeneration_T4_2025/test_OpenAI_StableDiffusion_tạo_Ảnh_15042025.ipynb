{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Báo Cáo So Sánh Các API Tạo Ảnh AI\n",
        "\n",
        "### Danh Sách API và Đặc Điểm Nổi Bật\n",
        "\n",
        "- *OpenAI DALL·E API*: Chất lượng ảnh rất cao, dễ tích hợp, tài liệu và SDK đầy đủ.\n",
        "- *Stability AI (Stable Diffusion)*: Nhiều tùy chỉnh, mô hình phong phú (SDXL, Stable Diffusion 3), hỗ trợ tự host hoặc cloud, hỗ trợ cả text-to-image và image-to-image.\n",
        "- *Leonardo AI*: Đa dạng mô hình, hỗ trợ ảnh & video chất lượng cao, hệ thống credit tiện lợi.\n",
        "- *Google Gemini (Imagen 3)*: Chất lượng ảnh rất tốt, tích hợp dễ dàng với Google Cloud, có tier miễn phí.\n",
        "- *DeepAI*: Dễ sử dụng, chi phí thấp, hỗ trợ nhiều ngôn ngữ lập trình.\n",
        "- *Midjourney (API không chính thức)*: Chất lượng ảnh nổi bật, nhưng có rủi ro về điều khoản sử dụng.\n",
        "\n",
        "### Phân Tích Chi Tiết\n",
        "\n",
        "### 1. *OpenAI DALL·E API*\n",
        "- *Điểm mạnh:* Chất lượng ảnh rất cao, dễ tích hợp, tài liệu và SDK đầy đủ.\n",
        "- *Chi phí:*\n",
        "  - DALL-E 3: $0.04/ảnh (1024×1024), $0.08/ảnh (1792×1024)\n",
        "  - DALL-E 2: $0.016/ảnh (1024×1024)\n",
        "- *Phù hợp nhất khi:* Bạn ưu tiên chất lượng ảnh cao, tích hợp nhanh, và có ngân sách hợp lý.\n",
        "\n",
        "### 2. *Stability AI (Stable Diffusion)*\n",
        "- *Điểm mạnh:* Nhiều tùy chỉnh, mô hình phong phú (SDXL, Stable Diffusion 3), hỗ trợ tự host hoặc sử dụng cloud API, hỗ trợ text-to-image và image-to-image.\n",
        "- *Chi phí:* Linh hoạt tùy chọn, có thể tự host để tối ưu chi phí.\n",
        "- *Phù hợp nhất khi:* Bạn muốn kiểm soát chi tiết, nhiều tùy chỉnh hoặc muốn tự vận hành hạ tầng.\n",
        "\n",
        "### 3. *Leonardo AI*\n",
        "- *Điểm mạnh:* Đa dạng mô hình, hỗ trợ tạo ảnh và video chất lượng cao, hệ thống credit tiện lợi.\n",
        "- *Chi phí:*\n",
        "  - Standard: $49/tháng (25,000 credit)\n",
        "  - Pro: $299/tháng (200,000 credit)\n",
        "- *Phù hợp nhất khi:* Bạn cần sự linh hoạt cao về nội dung đa phương tiện, tạo cả video và ảnh.\n",
        "\n",
        "### 4. *Google Gemini (Imagen 3)*\n",
        "- *Điểm mạnh:* Chất lượng ảnh rất tốt, dễ dàng tích hợp với các dịch vụ Google Cloud, có tier miễn phí.\n",
        "- *Chi phí:* Có phiên bản miễn phí giới hạn, chi phí theo nhu cầu sử dụng trên Google Cloud.\n",
        "- *Phù hợp nhất khi:* Bạn quen thuộc với Google Cloud, muốn tận dụng hạ tầng có sẵn của Google và cần chất lượng cao.\n",
        "\n",
        "### 5. *DeepAI*\n",
        "- *Điểm mạnh:* Dễ sử dụng, chi phí thấp, hỗ trợ nhiều ngôn ngữ lập trình.\n",
        "- *Chi phí:* Rất phải chăng, thích hợp cho dự án nhỏ hoặc thử nghiệm.\n",
        "- *Phù hợp nhất khi:* Bạn cần giải pháp nhanh gọn, ngân sách thấp và sử dụng không quá phức tạp.\n",
        "\n",
        "### Các Tùy Chọn API Không Chính Thức (Midjourney)\n",
        "- *Điểm mạnh:* Chất lượng ảnh nổi bật của Midjourney.\n",
        "- *Lưu ý:* Nguy cơ vi phạm điều khoản dịch vụ và khả năng bị khóa tài khoản.\n",
        "- *Phù hợp nhất khi:* Chấp nhận rủi ro, cần chất lượng ảnh từ Midjourney mà không có lựa chọn khác.\n",
        "\n",
        "---\n",
        "\n",
        "### Đề Xuất Chung:\n",
        "- *OpenAI DALL·E:* Nếu ưu tiên chất lượng và sự đơn giản.\n",
        "- *Stability AI:* Khi cần tùy chỉnh mạnh mẽ và tự kiểm soát.\n",
        "- *Google Gemini:* Phù hợp với hệ sinh thái Google, chất lượng cao, miễn phí thử nghiệm.\n",
        "\n",
        "### Lưu Ý Quan Trọng Khi Tích Hợp:\n",
        "- Luôn xử lý lỗi kỹ càng.\n",
        "- Kiểm soát giới hạn tốc độ API.\n",
        "- Quản lý chi phí hiệu quả.\n",
        "- Sử dụng bộ nhớ cache thông minh.\n",
        "- Chuẩn bị cho tình huống mạng không ổn định."
      ],
      "metadata": {
        "id": "BfiN3nzXswJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "anh @Truc Le Van ơi, con Gen ảnh của anh có đang bật không ạ.\n",
        "\n",
        "Tụi em vừa test thử 2 con: xài API Key là: Dall-e-3 (OPENAI) với Stable Diffusion.\n",
        "Kết quả Stable Diffusion gen ổn áp hơn.\n",
        "\n",
        "Giờ tụi em có 2 phương án:\n",
        "1. Là gen ảnh xài tool của a @Truc Le Van  (cũng model của Stable Diffusion).\n",
        "2. Là xài qua API Key và mất phí.\n",
        "Giá: KHOẢNG 0.08$ cho 1 ảnh\n",
        "\n",
        "---\n",
        "Link gen nhanh:\n",
        "- https://colab.research.google.com/github/stability-ai/stability-sdk/blob/main/nbs/Stable_Image_API_Public.ipynb#scrollTo=dtw-2LAC7NgM\n",
        "-"
      ],
      "metadata": {
        "id": "AZhgW1FUszZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subject - Features - Background\n",
        "2. Medium (/Type/category of artwork): Ultra realistic illustration (Drawings that are very realistic. Good to use with people.), concept art (Illustration style, 2D.), Digital painting(Digital art style), Digital, Digital Minimalist Illustration\n",
        "3. Style: Modernist(vibrant color, high contrast), pastel color,\n",
        "4. Art-sharing website, Artist: artstation(website Modern illustration, fantasy)\n",
        "5. Resolution: unreal engine\n",
        "6. Additional details\n",
        "7. Color: iridescent gold, pastel color (Màu sắc nhẹ nhàng), vibrant color (Màu sắc rực rỡ,), Soft color\n",
        "8. Lighting: cinematic lighting\n"
      ],
      "metadata": {
        "id": "E9mPhFsIsb24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bạn đã gửi\n",
        "Hôm nay lúc 16:02\n",
        "The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models."
      ],
      "metadata": {
        "id": "PqE0B7VXsd-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjlFUG4mMaaY",
        "outputId": "52367a99-bdb2-471d-bf48-a063aee8be06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "lqOsM9qVMJcS",
        "outputId": "73303b29-d8b2-4db8-8065-40921f2ded6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sk-pr\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'code': 'invalid_size', 'message': 'The size is not supported by this model.', 'param': None, 'type': 'invalid_request_error'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d906de7444c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Tạo ảnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m response = client.images.generate(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dall-e-3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/images.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;34m\"/images/generations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'invalid_size', 'message': 'The size is not supported by this model.', 'param': None, 'type': 'invalid_request_error'}}"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get OpenAI API key from environment variables\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "OPENAI_API_KEY = \"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\"\n",
        "print(OPENAI_API_KEY[0:5])\n",
        "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Prompt dạng chuỗi nhiều dòng\n",
        "image_prompt = \"\"\"\n",
        "You are illustration artist specializing in making flash cards for English learning.\n",
        "Given a context and a phrase, make a simple illustration that accurately represents its meaning.\n",
        "---\n",
        "Context: 'IT - Daily stand up'\n",
        "Phrase: 'writing test case.'\n",
        "\"\"\"\n",
        "\n",
        "# Tạo ảnh\n",
        "response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=image_prompt,\n",
        "    n=1,\n",
        "    size=\"256x256\"\n",
        ")\n",
        "\n",
        "# Lấy URL ảnh\n",
        "image_url = response.data[0].url\n",
        "\n",
        "# Tải ảnh về (tuỳ chọn)\n",
        "image_response = requests.get(image_url)\n",
        "img = Image.open(BytesIO(image_response.content))\n",
        "img.save(\"generated_image.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# https://colab.research.google.com/github/stability-ai/stability-sdk/blob/main/nbs/Stable_Image_API_Public.ipynb#scrollTo=dtw-2LAC7NgM"
      ],
      "metadata": {
        "id": "3xCRHy34smul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini"
      ],
      "metadata": {
        "id": "1mf8JRR5ssjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1PCXAvQs2JN",
        "outputId": "7414e668-b029-4a75-f2a7-f71f2a7c3537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ai.google.dev/gemini-api/docs/api-key"
      ],
      "metadata": {
        "id": "lqqKlWH9s9GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genaifrom google.genai import typesfrom PIL import Imagefrom io import BytesIOimport base64client = genai.Client()contents = ('Hi, can you create a 3d rendered image of a pig '\n",
        "\n",
        "            'with wings and a top hat flying over a happy '\n",
        "\n",
        "            'futuristic scifi city with lots of greenery?')response = client.models.generate_content(\n",
        "\n",
        "    model=\"gemini-2.0-flash-exp-image-generation\",\n",
        "\n",
        "    contents=contents,\n",
        "\n",
        "    config=types.GenerateContentConfig(\n",
        "\n",
        "      response_modalities=['TEXT', 'IMAGE']\n",
        "\n",
        "    ))for part in response.candidates[0].content.parts:\n",
        "\n",
        "  if part.text is not None:\n",
        "\n",
        "    print(part.text)\n",
        "\n",
        "  elif part.inline_data is not None:\n",
        "\n",
        "    image = Image.open(BytesIO((part.inline_data.data)))\n",
        "\n",
        "    image.save('gemini-native-image.png')\n",
        "\n",
        "    image.show()"
      ],
      "metadata": {
        "id": "Gfd9VkFcs4E5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "9c548e29-2c53-4d47-d48a-4f1925fa8e01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-a394a4046492>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a394a4046492>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from google import genaifrom google.genai import typesfrom PIL import Imagefrom io import BytesIOimport base64client = genai.Client()contents = ('Hi, can you create a 3d rendered image of a pig '\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import io\n",
        "import base64\n",
        "import PIL.Image\n",
        "from IPython.display import display\n",
        "\n",
        "API_KEY = \"AIzaSyAixkJFZB-KtZoSaJomxkf9WaWGHS1NQeI\"  # Replace with your actual API key\n",
        "API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\"\n",
        "\n",
        "def generate_image_via_rest(prompt):\n",
        "    \"\"\"Generate an image using the Gemini API via REST.\"\"\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"x-goog-api-key\": API_KEY\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"parts\": [\n",
        "                    {\n",
        "                        \"text\": f\"Generate an image based on this description: {prompt}\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"temperature\": 0.4,\n",
        "            \"topK\": 32,\n",
        "            \"topP\": 1,\n",
        "            \"maxOutputTokens\": 4096\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(API_URL, headers=headers, data=json.dumps(data))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_json = response.json()\n",
        "\n",
        "        # Extract image data if available\n",
        "        for candidate in response_json.get(\"candidates\", []):\n",
        "            for part in candidate.get(\"content\", {}).get(\"parts\", []):\n",
        "                if \"inlineData\" in part and part[\"inlineData\"][\"mimeType\"].startswith(\"image/\"):\n",
        "                    image_data = base64.b64decode(part[\"inlineData\"][\"data\"])\n",
        "                    return image_data\n",
        "\n",
        "        print(\"No image found in response\")\n",
        "        return None\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        print(response.text)\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "prompt = \"A serene mountain landscape with a lake reflecting the sunset and snow-capped peaks\"\n",
        "image_data = generate_image_via_rest(prompt)\n",
        "\n",
        "if image_data:\n",
        "    # Convert bytes to image and display\n",
        "    image = PIL.Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # Save image\n",
        "    image_path = \"generated_image.jpg\"\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Display image\n",
        "    display(image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXh53GXmtWhH",
        "outputId": "4750e7f2-110f-4fd8-b8c2-0ee56db98bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 404\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": 404,\n",
            "    \"message\": \"models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n",
            "    \"status\": \"NOT_FOUND\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8R8tkguetGyp"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}